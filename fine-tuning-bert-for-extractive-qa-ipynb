{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/susantaghosh/fine-tuning-bert-for-extractive-qa?scriptVersionId=96924287\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{"id":"3AzrVylgBfDX"}},{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/susantaghosh1/nlp-notebooks/blob/develop/Fine_Tuning_Extractive_QA_with_BERT_and_Friends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Fine Tuning BERT/RoBERTa/DeBERTa/ALBERT/DistillBERT for extractive QA on Squad dataset","metadata":{"id":"UWOCThD20H8r"}},{"cell_type":"markdown","source":"In this section we will fine-tune Extractive QA on Squad dataset. Encoder-only models like BERT tend to be great at extracting answers to factoid questions like “Who invented the Transformer architecture?” but fare poorly when given open-ended questions like “Why is the sky blue?” In these more challenging cases, encoder-decoder models like T5 and BART are typically used to synthesize the information in a way that’s quite similar to text summarization.","metadata":{"id":"-IdJqLwX0qNr"}},{"cell_type":"markdown","source":"All of those work in the same way: they add a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size,sequence_length,2), indicating the unnormalized scores **[LOGITS]** for start position and end position of the answers for every example in the batch.","metadata":{"id":"SSP9JjD9059z"}},{"cell_type":"markdown","source":"Let's discuss little bit internal working of the model :\n\n1. Question and Context [tokenized version] will be passed together as a pair to the model **[ let's say shape of input to the model is (5,30) where 5 is batch_size and 30 is sequence length [number of tokens in each input]**\n2. Vanilla BERT [OR it's friends] will produce contextualized embeddings for each and every word in the sequence. Shape of output from BERT is **(5,30,768) where 5 is the batch size, 30 is the sequece length and 768 is the embedding dimension of the each token**\n3. Now a linear head will be added on top of each of the tokens and each liner layer will take 768 dim as input and outputs 2 tensors , which we call start_logits and end_logits. Now, shape of output is **(5,30,2)**\n4. Now we will split the start_logits and end_logits where shape of each logits are **(5,30,1)**\n5. Now we will remove the single dimesion from the last dimension of start and end logits or in other words we will squeeze the start and end logits across the last dimesion and now shape of start and end logits will be **(5,30)**\n\n**start_logits = tensor of shape (5,30)**\n**end_logits = tensor of shape (5,30)**\n\n6. Model will take start_positions and end_positions of the answer in the tokenized data as labels\n\nstart_positions (`torch.LongTensor` of shape `(batch_size,)`):\n            Labels for position (index) of the start of the labelled span for computing the token classification loss.Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence are not taken into account for computing the loss.\n\nend_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n            Labels for position (index) of the end of the labelled span for computing the token classification loss.Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence are not taken into account for computing the loss.\n\n**start_positions = tensor of shape (5,)**\n**end_positions = tensor of shape (5,)**\n\n7. Now Cross Entropy loss will be computed between **start_logits and start_positions** and **end_logits and end_positions**.\n\n8. Total loss will be the average loss of **start_logits and start_positions** and end_logits and end_positions** and it will be backpropagated to the model for calculationg the gradients and optimizing the weights\n\nPseudo code for QA Model with BERT\n\nclass PseudoQA(nn.Module):\n\n  def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n\n        self.bert = BertModel(config, add_pooling_layer=False)\n        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n\n        # Initialize weights and apply final processing\n        self.post_init()\n  \n   def forward(\n        self,\n        input_ids: Optional[torch.Tensor] = None,\n        attention_mask: Optional[torch.Tensor] = None,\n        token_type_ids: Optional[torch.Tensor] = None,\n        start_positions: Optional[torch.Tensor] = None,\n        end_positions: Optional[torch.Tensor] = None,\n    ) :\n        \n        outputs = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=inputs_embeds,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n\n        sequence_output = outputs[0] ## ** last hidden state output of bert**\n\n        # ** shape of sequence_output : (batch_size,sequence_length,768) **\n\n        logits = self.qa_outputs(sequence_output)\n        # ** shape of logits : (batch_size,sequence_length,2) **\n        start_logits, end_logits = logits.split(1, dim=-1)\n        # ** shape of start_logits and end_logits : (batch_size,sequence_length,1) **\n        start_logits = start_logits.squeeze(-1).contiguous() # ** shape : (batch_size,sequence_length) **\n        end_logits = end_logits.squeeze(-1).contiguous() # ** shape : (batch_size,sequence_length) **\n\n        total_loss = None\n        if start_positions is not None and end_positions is not None:\n            # If we are on multi-GPU, split add a dimension\n            if len(start_positions.size()) > 1:\n                start_positions = start_positions.squeeze(-1)\n            if len(end_positions.size()) > 1:\n                end_positions = end_positions.squeeze(-1)\n            # sometimes the start/end positions are outside our model inputs, \n            # we ignore these terms\n            ignored_index = start_logits.size(1)\n            start_positions = start_positions.clamp(0, ignored_index)\n            end_positions = end_positions.clamp(0, ignored_index)\n\n            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n            start_loss = loss_fct(start_logits, start_positions)\n            end_loss = loss_fct(end_logits, end_positions)\n            total_loss = (start_loss + end_loss) / 2\n  \n\n","metadata":{"id":"rNXXtkju2Nni"}},{"cell_type":"markdown","source":"Enough of theory!!!! Let's dirty our hands","metadata":{"id":"_bBJUi-iNAuG"}},{"cell_type":"code","source":"%%capture\n!pip install datasets transformers[sentencepiece]\n!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n!pip install scipy sklearn","metadata":{"id":"8wtg2T5g6Epj","execution":{"iopub.status.busy":"2022-05-31T04:57:28.329577Z","iopub.execute_input":"2022-05-31T04:57:28.329994Z","iopub.status.idle":"2022-05-31T04:57:57.416437Z","shell.execute_reply.started":"2022-05-31T04:57:28.329915Z","shell.execute_reply":"2022-05-31T04:57:57.415405Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\ndevice","metadata":{"id":"fRNa7Cx0M8_W","outputId":"647c0f34-eca3-4bc0-e441-5b25f543c001","execution":{"iopub.status.busy":"2022-05-31T04:57:57.419397Z","iopub.execute_input":"2022-05-31T04:57:57.419969Z","iopub.status.idle":"2022-05-31T04:57:59.341548Z","shell.execute_reply.started":"2022-05-31T04:57:57.419926Z","shell.execute_reply":"2022-05-31T04:57:59.340762Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"ZyPHX3ByM_jd","outputId":"9eb721a1-e4d0-46a9-920b-2282937d90e3","execution":{"iopub.status.busy":"2022-05-31T04:57:59.342738Z","iopub.execute_input":"2022-05-31T04:57:59.343278Z","iopub.status.idle":"2022-05-31T04:58:00.034867Z","shell.execute_reply.started":"2022-05-31T04:57:59.343251Z","shell.execute_reply":"2022-05-31T04:58:00.033899Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Tue May 31 04:57:59 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   33C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# load the dataset\n\nfrom datasets import load_dataset\n\nraw_datasets = load_dataset(\"squad\")","metadata":{"id":"yF5FW2LuP4ZN","outputId":"10073e2e-86ec-4090-8ece-22b6cb9f4004","execution":{"iopub.status.busy":"2022-05-31T04:58:00.037118Z","iopub.execute_input":"2022-05-31T04:58:00.037420Z","iopub.status.idle":"2022-05-31T04:58:17.799572Z","shell.execute_reply.started":"2022-05-31T04:58:00.037393Z","shell.execute_reply":"2022-05-31T04:58:17.798704Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29909d1d61ca47e0b8793106bcad2a7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be2efd0aba34de98e5fc9bcd131a2b6"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"831630b6320848d19ab1c80a3c97a704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48f4b08cd2484814947b744ddd90cc54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29cb4a9b51474b08b8d748a55040ec3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f89da56a53d471eb658d2c571985291"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b126a634330c4dc1ac0b20091636a4e5"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"id":"EZ43kFkGQB92","outputId":"234e45c7-6549-4295-ed35-379e82259460","execution":{"iopub.status.busy":"2022-05-31T04:16:06.946339Z","iopub.execute_input":"2022-05-31T04:16:06.946849Z","iopub.status.idle":"2022-05-31T04:16:06.955953Z","shell.execute_reply.started":"2022-05-31T04:16:06.946800Z","shell.execute_reply":"2022-05-31T04:16:06.954502Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 87599\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 10570\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Context: \", raw_datasets[\"train\"][0][\"context\"])\nprint(\"Question: \", raw_datasets[\"train\"][0][\"question\"])\nprint(\"Answer: \", raw_datasets[\"train\"][0][\"answers\"])","metadata":{"id":"WmtmryzAQG5e","outputId":"bb0f30e0-9505-4f1f-b772-4839d5f9771f","execution":{"iopub.status.busy":"2022-05-29T11:30:49.996414Z","iopub.execute_input":"2022-05-29T11:30:49.997431Z","iopub.status.idle":"2022-05-29T11:30:50.086318Z","shell.execute_reply.started":"2022-05-29T11:30:49.997389Z","shell.execute_reply":"2022-05-29T11:30:50.085234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(raw_datasets[\"train\"][0][\"answers\"].keys())\nprint(type(raw_datasets[\"train\"][0][\"answers\"]['text']))\nprint(raw_datasets[\"train\"][0][\"answers\"]['text'][0])","metadata":{"id":"yvnINZheQWU3","outputId":"0056e6fb-cf78-4110-8efd-60ec91c345fb","execution":{"iopub.status.busy":"2022-05-29T11:30:50.088119Z","iopub.execute_input":"2022-05-29T11:30:50.089218Z","iopub.status.idle":"2022-05-29T11:30:50.097488Z","shell.execute_reply.started":"2022-05-29T11:30:50.089178Z","shell.execute_reply":"2022-05-29T11:30:50.096378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = raw_datasets[\"train\"][0][\"answers\"]['text'][0]\nanswer_start = raw_datasets[\"train\"][0][\"answers\"]['answer_start'][0]\nanswer_end = answer_start + len(answer)\nanswer_from_context = raw_datasets[\"train\"][0][\"context\"] [answer_start:answer_end]\n","metadata":{"id":"LdlXXwrnQtmG","execution":{"iopub.status.busy":"2022-05-29T11:30:50.099256Z","iopub.execute_input":"2022-05-29T11:30:50.09973Z","iopub.status.idle":"2022-05-29T11:30:50.107758Z","shell.execute_reply.started":"2022-05-29T11:30:50.099685Z","shell.execute_reply":"2022-05-29T11:30:50.106856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer_from_context","metadata":{"id":"58sejr9eRPYw","outputId":"3665f685-8d37-4b2c-87b6-42eb045fb7bb","execution":{"iopub.status.busy":"2022-05-29T11:30:50.109237Z","iopub.execute_input":"2022-05-29T11:30:50.110233Z","iopub.status.idle":"2022-05-29T11:30:50.118052Z","shell.execute_reply.started":"2022-05-29T11:30:50.110193Z","shell.execute_reply":"2022-05-29T11:30:50.117075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"During training, there is only one possible answer. We can double-check this by using the Dataset.filter() method:","metadata":{"id":"-d-TVnBFTL0u"}},{"cell_type":"code","source":"raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)","metadata":{"id":"o1Ut4701TMxO","outputId":"8dc73478-af8a-4291-adab-469fc275ac91","execution":{"iopub.status.busy":"2022-05-29T11:30:50.120459Z","iopub.execute_input":"2022-05-29T11:30:50.121125Z","iopub.status.idle":"2022-05-29T11:30:52.681932Z","shell.execute_reply.started":"2022-05-29T11:30:50.121082Z","shell.execute_reply":"2022-05-29T11:30:52.681039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For evaluation, however, there are several possible answers for each sample, which may be the same or different:","metadata":{"id":"bfbqU4vJTZhm"}},{"cell_type":"code","source":"print(raw_datasets[\"validation\"][0][\"answers\"])\nprint(raw_datasets[\"validation\"][2][\"answers\"])","metadata":{"id":"2qLBYycwTa8A","outputId":"f2599b0e-60a7-4635-ae5a-a7df7ebb140b","execution":{"iopub.status.busy":"2022-05-29T11:30:52.683415Z","iopub.execute_input":"2022-05-29T11:30:52.683972Z","iopub.status.idle":"2022-05-29T11:30:52.690463Z","shell.execute_reply.started":"2022-05-29T11:30:52.683914Z","shell.execute_reply":"2022-05-29T11:30:52.6896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PreProcessing the training data","metadata":{"id":"xM--6qJeTqOf"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"id":"2BktODGOTxon","outputId":"ddbf8d1f-2931-4caf-ec3e-308b4817bde8","execution":{"iopub.status.busy":"2022-05-29T11:30:52.691909Z","iopub.execute_input":"2022-05-29T11:30:52.692475Z","iopub.status.idle":"2022-05-29T11:30:54.692115Z","shell.execute_reply.started":"2022-05-29T11:30:52.692435Z","shell.execute_reply":"2022-05-29T11:30:54.69115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.is_fast,tokenizer.special_tokens_map","metadata":{"id":"yD-6GHL-T23H","outputId":"549dfe47-4711-46dc-ed03-e025e709669f","execution":{"iopub.status.busy":"2022-05-29T11:30:54.693419Z","iopub.execute_input":"2022-05-29T11:30:54.693807Z","iopub.status.idle":"2022-05-29T11:30:54.702086Z","shell.execute_reply.started":"2022-05-29T11:30:54.693769Z","shell.execute_reply":"2022-05-29T11:30:54.701269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can pass to our tokenizer the question and the context together, and it will properly insert the special tokens to form a sentence like this:\n\nCopied\n[CLS] question [SEP] context [SEP]","metadata":{"id":"p34OEOUMUA_X"}},{"cell_type":"markdown","source":"a predicted answer to all the acceptable answers and take the best score. ","metadata":{"id":"mzFGnoH6TlpQ"}},{"cell_type":"markdown","source":"","metadata":{"id":"SsG8T3v3amQX"}},{"cell_type":"code","source":"context = raw_datasets[\"train\"][0][\"context\"]\nquestion = raw_datasets[\"train\"][0][\"question\"]\n\ninputs = tokenizer(question, context,return_offsets_mapping=True)\n","metadata":{"id":"FMfQjUUDUDaH","execution":{"iopub.status.busy":"2022-05-29T11:30:54.706903Z","iopub.execute_input":"2022-05-29T11:30:54.707596Z","iopub.status.idle":"2022-05-29T11:30:54.808269Z","shell.execute_reply.started":"2022-05-29T11:30:54.707553Z","shell.execute_reply":"2022-05-29T11:30:54.807353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(inputs['input_ids']),len(inputs['offset_mapping']),inputs","metadata":{"id":"CEBR0FpJVF9L","outputId":"9c14a329-3f2a-47d5-f7e7-aab822b373c2","execution":{"iopub.status.busy":"2022-05-29T11:30:54.810439Z","iopub.execute_input":"2022-05-29T11:30:54.81113Z","iopub.status.idle":"2022-05-29T11:30:54.819257Z","shell.execute_reply.started":"2022-05-29T11:30:54.811089Z","shell.execute_reply":"2022-05-29T11:30:54.818265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(inputs[\"input_ids\"])\n","metadata":{"id":"uO3b74dQUZlX","outputId":"b6c2379b-faa3-4b9a-a472-49e703c4c8d6","execution":{"iopub.status.busy":"2022-05-29T11:30:54.8209Z","iopub.execute_input":"2022-05-29T11:30:54.821995Z","iopub.status.idle":"2022-05-29T11:30:56.453375Z","shell.execute_reply.started":"2022-05-29T11:30:54.821951Z","shell.execute_reply":"2022-05-29T11:30:56.452564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])","metadata":{"id":"169dwirTUwLf","outputId":"6dc9c854-2839-4dc2-a745-ed70fb017af6","execution":{"iopub.status.busy":"2022-05-29T11:30:56.455031Z","iopub.execute_input":"2022-05-29T11:30:56.455794Z","iopub.status.idle":"2022-05-29T11:30:56.464992Z","shell.execute_reply.started":"2022-05-29T11:30:56.455757Z","shell.execute_reply":"2022-05-29T11:30:56.464119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case the context is not too long, but some of the examples in the dataset have very long contexts that will exceed the maximum length we set (which is 384 in this case).  we will deal with long contexts by creating several training features from one sample of our dataset, with a sliding window between them.\n\nTo see how this works using the current example, we can limit the length to 100 and use a sliding window of 50 tokens. As a reminder, we use:\n\nmax_length to set the maximum length (here 100)\ntruncation=\"only_second\" to truncate the context (which is in the second position) when the question with its context is too long\nstride to set the number of overlapping tokens between two successive chunks (here 50)\nreturn_overflowing_tokens=True to let the tokenizer know we want the overflowing tokens\n\nreturn_offsets_mapping=True to get the positions of the tokens with respect to the input of the tokenizer [for sequence_id =0, position of question otherwise positions of context]","metadata":{"id":"WqU8pIIPbWyo"}},{"cell_type":"code","source":"batch_encoding = tokenizer(question,context,max_length=100,truncation=\"only_second\",stride=50,\n                           return_overflowing_tokens=True,return_offsets_mapping=True)","metadata":{"id":"WbB-14qsb21H","execution":{"iopub.status.busy":"2022-05-29T11:30:56.466568Z","iopub.execute_input":"2022-05-29T11:30:56.466945Z","iopub.status.idle":"2022-05-29T11:30:56.475535Z","shell.execute_reply.started":"2022-05-29T11:30:56.466909Z","shell.execute_reply":"2022-05-29T11:30:56.474511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_encoding.keys(),len(batch_encoding['input_ids'])","metadata":{"id":"trnC18RWc-w5","outputId":"ac04e23a-33e3-44d2-c2b4-73530f5656e9","execution":{"iopub.status.busy":"2022-05-29T11:30:56.478378Z","iopub.execute_input":"2022-05-29T11:30:56.478931Z","iopub.status.idle":"2022-05-29T11:30:56.485772Z","shell.execute_reply.started":"2022-05-29T11:30:56.478904Z","shell.execute_reply":"2022-05-29T11:30:56.484992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_encoding","metadata":{"id":"eYxd_MnpeIAS","outputId":"0e1476b4-c3ed-42cf-95ac-c20b041d0fe9","execution":{"iopub.status.busy":"2022-05-29T11:30:56.487032Z","iopub.execute_input":"2022-05-29T11:30:56.48765Z","iopub.status.idle":"2022-05-29T11:30:56.498491Z","shell.execute_reply.started":"2022-05-29T11:30:56.487612Z","shell.execute_reply":"2022-05-29T11:30:56.497525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_encoding['overflow_to_sample_mapping'] # one long context has been truncated to 4 samples","metadata":{"id":"B13HJSF1dO14","outputId":"af2a18ed-81fd-4560-c59b-672317501136","execution":{"iopub.status.busy":"2022-05-29T11:30:56.499478Z","iopub.execute_input":"2022-05-29T11:30:56.501748Z","iopub.status.idle":"2022-05-29T11:30:56.508531Z","shell.execute_reply.started":"2022-05-29T11:30:56.501703Z","shell.execute_reply":"2022-05-29T11:30:56.507561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_ids = batch_encoding.sequence_ids(0)\nsliced_text = \"\"\nfor idx,tokens,positions in zip(range(len(batch_encoding['input_ids'][0])),batch_encoding['input_ids'][0],batch_encoding['offset_mapping'][0]):\n  if sequence_ids[idx]==0:\n    sliced_text = question[positions[0]:positions[1]]\n  elif sequence_ids[idx]==1:\n    sliced_text = context[positions[0]:positions[1]]\n  print(f\"tokens :: {tokens} and decoed token :: {tokenizer.convert_ids_to_tokens(tokens)} and positions :: {positions} and sliced  text :: {sliced_text}\")  ## positions for special tokens will be (0,0)","metadata":{"id":"8FlXbGwpdYBq","outputId":"06c047b4-1f5e-4483-fc25-e07b93b38998","execution":{"iopub.status.busy":"2022-05-29T11:30:56.510344Z","iopub.execute_input":"2022-05-29T11:30:56.510986Z","iopub.status.idle":"2022-05-29T11:30:56.52155Z","shell.execute_reply.started":"2022-05-29T11:30:56.510947Z","shell.execute_reply":"2022-05-29T11:30:56.52054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's try to encode few more samples together\n\nsample_question =  raw_datasets[\"train\"][2:6][\"question\"] # list of size 4\nsample_context =  raw_datasets[\"train\"][2:6][\"context\"] # list of size 4\nsample_answers = raw_datasets[\"train\"][2:6][\"answers\"]\nsample_question,sample_question[0],sample_context[0],sample_answers[0]","metadata":{"id":"X6fFEkM7mbN4","outputId":"303cc061-4d09-417c-ee34-1f1a0303f0d7","execution":{"iopub.status.busy":"2022-05-29T11:30:56.523478Z","iopub.execute_input":"2022-05-29T11:30:56.523954Z","iopub.status.idle":"2022-05-29T11:30:56.535184Z","shell.execute_reply.started":"2022-05-29T11:30:56.52391Z","shell.execute_reply":"2022-05-29T11:30:56.534174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_encoding = tokenizer(sample_question,sample_context,max_length=100,truncation=\"only_second\",stride=50,\n                           return_overflowing_tokens=True,return_offsets_mapping=True)\nsample_encoding,sample_encoding.keys(),len(sample_encoding['offset_mapping'][0])","metadata":{"id":"Ub23TiWkm4Ao","outputId":"abb9e86a-1f7f-4abb-d7ef-106a4a5feb81","execution":{"iopub.status.busy":"2022-05-29T11:30:56.53742Z","iopub.execute_input":"2022-05-29T11:30:56.537979Z","iopub.status.idle":"2022-05-29T11:30:56.551964Z","shell.execute_reply.started":"2022-05-29T11:30:56.537941Z","shell.execute_reply":"2022-05-29T11:30:56.550779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k,v in sample_encoding.items():\n  print(f\"shape of {k} :: {len(v)}\")  # 4 inputs  results in 19 samples","metadata":{"id":"cUHLHqZInL_Z","outputId":"406073e9-2286-42be-be71-7c5ec36808c8","execution":{"iopub.status.busy":"2022-05-29T11:30:56.553482Z","iopub.execute_input":"2022-05-29T11:30:56.554074Z","iopub.status.idle":"2022-05-29T11:30:56.560684Z","shell.execute_reply.started":"2022-05-29T11:30:56.554034Z","shell.execute_reply":"2022-05-29T11:30:56.559725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"input_ids ,token_type_ids,attention_mask,offset_mapping : each of them will be list of lists and overflow_to_sample_mapping will be simple list","metadata":{"id":"1lniCdkWGAGH"}},{"cell_type":"markdown","source":"let's make the labels. labels will be start_positions and end_positions where each of them will be of shape (batch_size)","metadata":{"id":"01Lpv5pVGiEZ"}},{"cell_type":"markdown","source":"(0, 0) if the answer is not in the corresponding span of the context\n(start_position, end_position) if the answer is in the corresponding span of the context, with start_position being the index of the token (in the input IDs) at the start of the answer and end_position being the index of the token (in the input IDs) where the answer ends","metadata":{"id":"Cz_Hiu5fpI64"}},{"cell_type":"code","source":"sample_answers = raw_datasets[\"train\"][2:6][\"answers\"]\nsample_answers,sample_answers[0]","metadata":{"id":"A00Datp9pLAx","outputId":"e4afa8bf-bf9d-4574-a470-0d9fceb8fc72","execution":{"iopub.status.busy":"2022-05-29T11:30:56.562624Z","iopub.execute_input":"2022-05-29T11:30:56.563293Z","iopub.status.idle":"2022-05-29T11:30:56.573575Z","shell.execute_reply.started":"2022-05-29T11:30:56.563255Z","shell.execute_reply":"2022-05-29T11:30:56.572381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_encoding['overflow_to_sample_mapping']\n","metadata":{"id":"EMM2UPpbrFJ5","outputId":"763c3589-b7b6-4abe-cbe8-335beb6c7d00","execution":{"iopub.status.busy":"2022-05-29T11:30:56.574693Z","iopub.execute_input":"2022-05-29T11:30:56.575566Z","iopub.status.idle":"2022-05-29T11:30:56.584074Z","shell.execute_reply.started":"2022-05-29T11:30:56.575537Z","shell.execute_reply":"2022-05-29T11:30:56.583072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find the original sample\n# find answers start and end char positions of that original sample\n# Find the start and end of the context\n# If the answer is not fully inside the context, label is (0, 0)\n# Otherwise it's the start and end token positions\nsample_mappings = sample_encoding['overflow_to_sample_mapping']\nstart_positions = []\nend_positions = []\nfor i,offset in enumerate(sample_encoding['offset_mapping']):\n  original_sample_id = sample_mappings[i] #find the original sample\n  answer = sample_answers[original_sample_id]\n  answer_start = answer['answer_start'][0]\n  answer_end = answer_start+len(answer['text'][0])\n  sequence_id = sample_encoding.sequence_ids(i)\n  idx = 0\n  while sequence_id[idx]!=1:\n    idx +=1\n  context_start = idx\n  while sequence_id[idx]==1:\n    idx +=1\n  context_end = idx-1\n  if offset[context_start][0]>answer_start or offset[context_end][1]<answer_end:\n    start_positions.append(0)\n    end_positions.append(0)\n  else:\n    idx = context_start\n    while idx <= context_end and offset[idx][0] <= answer_start:\n      idx +=1\n    start_positions.append(idx-1)\n    idx = context_end\n    while idx >= context_start and offset[idx][1] >= answer_end:\n      idx -= 1\n    end_positions.append(idx+1)\nstart_positions, end_positions\n\n\n","metadata":{"id":"Mwr4808TNkD5","outputId":"c4e09c83-2df4-4ad0-f493-4b483887e8b0","execution":{"iopub.status.busy":"2022-05-29T11:30:56.586163Z","iopub.execute_input":"2022-05-29T11:30:56.586909Z","iopub.status.idle":"2022-05-29T11:30:56.604229Z","shell.execute_reply.started":"2022-05-29T11:30:56.586834Z","shell.execute_reply":"2022-05-29T11:30:56.603362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let’s take a look at a few results to verify that our approach is correct. For the first feature we find (83, 85) as labels, so let’s compare the theoretical answer with the decoded span of tokens from 83 to 85 (inclusive):","metadata":{"id":"hqh_JX2ygMdP"}},{"cell_type":"code","source":"idx = 0\nsample_idx = sample_encoding[\"overflow_to_sample_mapping\"][idx]\nanswer = sample_answers[sample_idx][\"text\"][0]\n\nstart = start_positions[idx]\nend = end_positions[idx]\nlabeled_answer = tokenizer.decode(sample_encoding[\"input_ids\"][idx][start : end + 1])\n\nprint(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")","metadata":{"id":"fSIHC2WLf09v","outputId":"7f60c782-e4e6-4221-cc4d-116c24bc4249","execution":{"iopub.status.busy":"2022-05-29T11:30:56.607559Z","iopub.execute_input":"2022-05-29T11:30:56.608361Z","iopub.status.idle":"2022-05-29T11:30:56.617551Z","shell.execute_reply.started":"2022-05-29T11:30:56.608317Z","shell.execute_reply":"2022-05-29T11:30:56.61668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 4\nsample_idx = sample_encoding[\"overflow_to_sample_mapping\"][idx]\nanswer = sample_answers[sample_idx][\"text\"][0]\n\ndecoded_example = tokenizer.decode(sample_encoding[\"input_ids\"][idx])\nprint(f\"Theoretical answer: {answer}, decoded example: {decoded_example}\") #we don’t see the answer inside the context.","metadata":{"id":"TVH1fHz8geo2","outputId":"44cb4ae3-93bc-4b7e-8736-ae7ad6f75162","execution":{"iopub.status.busy":"2022-05-29T11:30:56.619068Z","iopub.execute_input":"2022-05-29T11:30:56.619762Z","iopub.status.idle":"2022-05-29T11:30:56.629393Z","shell.execute_reply.started":"2022-05-29T11:30:56.61972Z","shell.execute_reply":"2022-05-29T11:30:56.628386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 384\nstride = 128\n\n\ndef preprocess_training_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = sample_map[i]\n        answer = answers[sample_idx]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label is (0, 0)\n        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"id":"J6gbBlt2P_ef","execution":{"iopub.status.busy":"2022-05-29T11:30:56.63091Z","iopub.execute_input":"2022-05-29T11:30:56.631487Z","iopub.status.idle":"2022-05-29T11:30:56.648218Z","shell.execute_reply.started":"2022-05-29T11:30:56.63145Z","shell.execute_reply":"2022-05-29T11:30:56.647224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = raw_datasets.map(\n    preprocess_training_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)","metadata":{"id":"BI9g_21Yi-UF","outputId":"206bb5f1-0e47-4c5d-d123-1af4f45f581f","execution":{"iopub.status.busy":"2022-05-29T11:30:56.65211Z","iopub.execute_input":"2022-05-29T11:30:56.653616Z","iopub.status.idle":"2022-05-29T11:32:30.578039Z","shell.execute_reply.started":"2022-05-29T11:30:56.65357Z","shell.execute_reply":"2022-05-29T11:32:30.577166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset","metadata":{"id":"qRSx5u0kovqK","outputId":"a36d1375-9f78-415d-a27e-d275f3e67834","execution":{"iopub.status.busy":"2022-05-29T11:32:30.580125Z","iopub.execute_input":"2022-05-29T11:32:30.580658Z","iopub.status.idle":"2022-05-29T11:32:30.588082Z","shell.execute_reply.started":"2022-05-29T11:32:30.58062Z","shell.execute_reply":"2022-05-29T11:32:30.587402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine Tuning the **model**","metadata":{"id":"-FAj0tksCDiV"}},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"id":"PRXfJP5TlFZV","outputId":"a5ccc05f-e531-47be-bb46-070d9cdbd44b","execution":{"iopub.status.busy":"2022-05-29T11:32:30.589384Z","iopub.execute_input":"2022-05-29T11:32:30.589882Z","iopub.status.idle":"2022-05-29T11:32:50.598122Z","shell.execute_reply.started":"2022-05-29T11:32:30.589843Z","shell.execute_reply":"2022-05-29T11:32:50.597227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"uRzgvx9JlxC7","outputId":"8488d4ea-a01a-4385-d07f-bdd8e9aca6e7","execution":{"iopub.status.busy":"2022-05-29T11:35:45.562072Z","iopub.execute_input":"2022-05-29T11:35:45.562485Z","iopub.status.idle":"2022-05-29T11:35:45.655739Z","shell.execute_reply.started":"2022-05-29T11:35:45.562451Z","shell.execute_reply":"2022-05-29T11:35:45.654885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install git-lfs","metadata":{"id":"zXdRB9fTnvhi","outputId":"84fbc36c-5a5c-44c5-9552-2ec23f7e8704","execution":{"iopub.status.busy":"2022-05-29T11:34:31.096148Z","iopub.execute_input":"2022-05-29T11:34:31.097325Z","iopub.status.idle":"2022-05-29T11:34:33.276152Z","shell.execute_reply.started":"2022-05-29T11:34:31.097252Z","shell.execute_reply":"2022-05-29T11:34:33.275107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"bert-finetuned-squad\",\n    evaluation_strategy=\"no\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    fp16=True,\n    push_to_hub=True,\n)","metadata":{"id":"4GeGeRDwnOAF","execution":{"iopub.status.busy":"2022-05-29T11:36:04.776911Z","iopub.execute_input":"2022-05-29T11:36:04.777442Z","iopub.status.idle":"2022-05-29T11:36:04.789796Z","shell.execute_reply.started":"2022-05-29T11:36:04.777398Z","shell.execute_reply":"2022-05-29T11:36:04.788843Z"},"outputId":"e04fdc29-c285-4e38-bac4-4b75ebfe4b97","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:36:08.085356Z","iopub.execute_input":"2022-05-29T11:36:08.08602Z","iopub.status.idle":"2022-05-29T11:36:08.090176Z","shell.execute_reply.started":"2022-05-29T11:36:08.085977Z","shell.execute_reply":"2022-05-29T11:36:08.089322Z"},"id":"YPWVlC-yBfDu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['validation'],\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"id":"OyhJ8giuncnS","outputId":"457d5334-2283-474a-839f-ecc3440ac380","execution":{"iopub.status.busy":"2022-05-29T11:36:10.601397Z","iopub.execute_input":"2022-05-29T11:36:10.602372Z","iopub.status.idle":"2022-05-29T14:55:10.76791Z","shell.execute_reply.started":"2022-05-29T11:36:10.602309Z","shell.execute_reply":"2022-05-29T14:55:10.766872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating the model","metadata":{"id":"zxYK3gB6CUcW"}},{"cell_type":"markdown","source":"In huggingface QA pipeline or TransformerReader in haystack inference occurs in below steps\n\n1. Model will output **start_logit and end logit** for each tokens in the batch\n2. We will mask logits of question as well as padding tokens\n3. Convert the logits into probabilities by taking softmax\n4. calculate score of each **(start_logit,end_logit)** pairs by taking product [matrix multiplication] of the two probabilites\n5. look for the pair with the maximum score that yielded a valid answer (e.g., a start_token lower than end_token).","metadata":{"id":"tC7Br4XsCp2l"}},{"cell_type":"markdown","source":"To speed up the evalutation step we will change above steps a little bit\n\n1. We will exclude the softmax step [ logit score will be sufficient]\n2. Instead of calculating core of each (start_logit,end_logit) pairs, we will sort the start and end logits and select **n_best** logits where n_best will be a user defined parameter like 5,20 etc.\n3. Since we will skip the softmax, those scores will be logit scores, and will be obtained by taking the sum of the start and end logits (instead of the product, because of the rule **log(ab) = log(a) + log(b).**","metadata":{"id":"fu2G0okND9Dd"}},{"cell_type":"markdown","source":"Let's make small batch of 100 documents from validation set and evaluate our model","metadata":{"id":"cVayJ7n9JNQ0"}},{"cell_type":"code","source":"batch = raw_datasets[\"validation\"].shuffle().select(range(8))\nbatch","metadata":{"id":"6G92iQabJkEW","outputId":"1e47cfad-47de-438a-f491-e788112214c8","execution":{"iopub.status.busy":"2022-05-31T04:58:17.803326Z","iopub.execute_input":"2022-05-31T04:58:17.805692Z","iopub.status.idle":"2022-05-31T04:58:17.829957Z","shell.execute_reply.started":"2022-05-31T04:58:17.805650Z","shell.execute_reply":"2022-05-31T04:58:17.829270Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'title', 'context', 'question', 'answers'],\n    num_rows: 8\n})"},"metadata":{}}]},{"cell_type":"code","source":"for each_document in batch:\n  break\neach_document","metadata":{"id":"PQeyN5DlJ0UM","outputId":"b3349e1a-77cd-4cac-a708-00c76a65c188","execution":{"iopub.status.busy":"2022-05-31T04:58:17.833589Z","iopub.execute_input":"2022-05-31T04:58:17.836023Z","iopub.status.idle":"2022-05-31T04:58:17.850894Z","shell.execute_reply.started":"2022-05-31T04:58:17.835985Z","shell.execute_reply":"2022-05-31T04:58:17.849949Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'id': '57264a8cdd62a815002e808d',\n 'title': 'European_Union_law',\n 'context': 'The European Commission is the main executive body of the European Union. Article 17(1) of the Treaty on European Union states the Commission should \"promote the general interest of the Union\" while Article 17(3) adds that Commissioners should be \"completely independent\" and not \"take instructions from any Government\". Under article 17(2), \"Union legislative acts may only be adopted on the basis of a Commission proposal, except where the Treaties provide otherwise.\" This means that the Commission has a monopoly on initiating the legislative procedure, although the Council is the \"de facto catalyst of many legislative initiatives\". The Parliament can also formally request the Commission to submit a legislative proposal but the Commission can reject such a suggestion, giving reasons. The Commission\\'s President (currently an ex-Luxembourg Prime Minister, Jean-Claude Juncker) sets the agenda for the EU\\'s work. Decisions are taken by a simple majority vote, usually through a \"written procedure\" of circulating the proposals and adopting if there are no objections.[citation needed] Since Ireland refused to consent to changes in the Treaty of Lisbon 2007, there remains one Commissioner for each of the 28 member states, including the President and the High Representative for Foreign and Security Policy (currently Federica Mogherini). The Commissioners (and most importantly, the portfolios they will hold) are bargained over intensively by the member states. The Commissioners, as a block, are then subject to a qualified majority vote of the Council to approve, and majority approval of the Parliament. The proposal to make the Commissioners be drawn from the elected Parliament, was not adopted in the Treaty of Lisbon. This means Commissioners are, through the appointment process, the unelected subordinates of member state governments.',\n 'question': 'Who is the sole governing authority capable of initiating legislative proposals?',\n 'answers': {'text': ['the Commission',\n   'The European Commission',\n   'the Commission',\n   'the Commission'],\n  'answer_start': [487, 0, 487, 487]}}"},"metadata":{}}]},{"cell_type":"code","source":"trained_model_checkpoint = 'susghosh/bert-finetuned-squad'\nfrom transformers import AutoTokenizer,AutoModelForQuestionAnswering\ntokenizer = AutoTokenizer.from_pretrained(trained_model_checkpoint)\nimport torch\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(trained_model_checkpoint).to(device)","metadata":{"id":"JWJAhRjHKLN9","execution":{"iopub.status.busy":"2022-05-31T04:58:17.855158Z","iopub.execute_input":"2022-05-31T04:58:17.855877Z","iopub.status.idle":"2022-05-31T04:58:52.423513Z","shell.execute_reply.started":"2022-05-31T04:58:17.855817Z","shell.execute_reply":"2022-05-31T04:58:52.422610Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/321 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"277d0cf586eb4dc5a4da284f722c2043"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbae8e93b32a440fa9ccc7449cd37c7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/695k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bca09fad8324eb7a6e3ac738194afae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4156962d52f4c9ca926a2084f024b39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/673 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"434144912d3848b58d40588de8549a57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c670aa0a43874b518114e415763e7d9b"}},"metadata":{}}]},{"cell_type":"code","source":"max_length = 384\nstride = 128\ndef pre_process_small_batch(example):\n   inputs = tokenizer(\n        example['question'],\n        example[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n   return inputs\nbatch_encoding = batch.map(pre_process_small_batch,batched=True,remove_columns=raw_datasets[\"validation\"].column_names,)","metadata":{"id":"45XS1VzKLSpo","outputId":"86aae68c-f0b8-43b3-abef-c25e793fc74b","execution":{"iopub.status.busy":"2022-05-31T04:58:52.621646Z","iopub.execute_input":"2022-05-31T04:58:52.623741Z","iopub.status.idle":"2022-05-31T04:58:52.807534Z","shell.execute_reply.started":"2022-05-31T04:58:52.623701Z","shell.execute_reply":"2022-05-31T04:58:52.806581Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aee3d835451043e5a3a36084054836b1"}},"metadata":{}}]},{"cell_type":"code","source":"batch_encoding, len(batch_encoding) ## 100 documents have been splitted among 101 documents","metadata":{"id":"E4PMo0njNEzx","outputId":"493b0f6b-b15b-4fea-b922-0bd10381197c","execution":{"iopub.status.busy":"2022-05-31T04:59:00.067596Z","iopub.execute_input":"2022-05-31T04:59:00.070066Z","iopub.status.idle":"2022-05-31T04:59:00.075357Z","shell.execute_reply.started":"2022-05-31T04:59:00.070031Z","shell.execute_reply":"2022-05-31T04:59:00.074573Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'],\n     num_rows: 8\n }),\n 8)"},"metadata":{}}]},{"cell_type":"code","source":"batch_offset_mapping = batch_encoding['offset_mapping']\nbatch_sample_mapping = batch_encoding['overflow_to_sample_mapping']\nbatch_encoding = batch_encoding.remove_columns(['offset_mapping','overflow_to_sample_mapping'])\nbatch_encoding.set_format('torch')","metadata":{"id":"1Ti0FZpMNo8X","execution":{"iopub.status.busy":"2022-05-31T04:59:04.199098Z","iopub.execute_input":"2022-05-31T04:59:04.199758Z","iopub.status.idle":"2022-05-31T04:59:04.219459Z","shell.execute_reply.started":"2022-05-31T04:59:04.199719Z","shell.execute_reply":"2022-05-31T04:59:04.218709Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"batch_encoding,batch_encoding.column_names","metadata":{"id":"3xNUIopTO3Lf","outputId":"a4f5c250-c1d9-4c6c-f41e-b56ef4de6531","execution":{"iopub.status.busy":"2022-05-31T04:59:07.064500Z","iopub.execute_input":"2022-05-31T04:59:07.065071Z","iopub.status.idle":"2022-05-31T04:59:07.070817Z","shell.execute_reply.started":"2022-05-31T04:59:07.065039Z","shell.execute_reply":"2022-05-31T04:59:07.069853Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['input_ids', 'token_type_ids', 'attention_mask'],\n     num_rows: 8\n }),\n ['input_ids', 'token_type_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"input_for_model ={k : batch_encoding[k].to(device) for k in batch_encoding.column_names}","metadata":{"id":"FSK89asEO-kf","execution":{"iopub.status.busy":"2022-05-31T04:59:09.524815Z","iopub.execute_input":"2022-05-31T04:59:09.525636Z","iopub.status.idle":"2022-05-31T04:59:09.532229Z","shell.execute_reply.started":"2022-05-31T04:59:09.525601Z","shell.execute_reply":"2022-05-31T04:59:09.531327Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n output = model(**input_for_model)","metadata":{"id":"8skd1qwnOwXV","outputId":"32440eb3-d635-4ae6-d664-c0272fade994","execution":{"iopub.status.busy":"2022-05-31T04:59:12.917900Z","iopub.execute_input":"2022-05-31T04:59:12.918283Z","iopub.status.idle":"2022-05-31T04:59:13.803386Z","shell.execute_reply.started":"2022-05-31T04:59:12.918252Z","shell.execute_reply":"2022-05-31T04:59:13.802578Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"output.start_logits.shape,output.end_logits.shape, ## each of the logits should be (batch_size,384)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:59:16.926522Z","iopub.execute_input":"2022-05-31T04:59:16.927402Z","iopub.status.idle":"2022-05-31T04:59:16.934164Z","shell.execute_reply.started":"2022-05-31T04:59:16.927359Z","shell.execute_reply":"2022-05-31T04:59:16.933269Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(torch.Size([8, 384]), torch.Size([8, 384]))"},"metadata":{}}]},{"cell_type":"code","source":"# let's grab the first logit\n# select n_best logits\n#for each start_logits score (each_start_logits,each_end_logits)\n#sort the score\nn_best_size = 20\nimport numpy as np\nidx =0 \nstart_logits = output.start_logits[idx].cpu().numpy()\nend_logits = output.end_logits[idx].cpu().numpy()\nstart_indices = np.argsort(start_logits)[-1:-n_best_size-1:-1].tolist()\nend_indices = np.argsort(end_logits)[-1:-n_best_size-1:-1].tolist()\nanswers = []\nfor each_start_index in start_indices:\n    for each_end_index in end_indices:\n        if(each_start_index<=each_end_index):\n            logit_score = start_logits[each_start_index]+end_logits[each_end_index]\n            context = batch['context'][batch_sample_mapping[idx]]\n            answer_start,_ = batch_offset_mapping[idx][each_start_index]\n            _,answer_end = batch_offset_mapping[idx][each_end_index]\n            answer = context[answer_start:answer_end]\n            answers.append({'logit_score':logit_score,'answer':answer})\nbest_answer = max(answers,key = lambda x: x['logit_score'])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:59:19.427023Z","iopub.execute_input":"2022-05-31T04:59:19.427373Z","iopub.status.idle":"2022-05-31T04:59:19.481870Z","shell.execute_reply.started":"2022-05-31T04:59:19.427344Z","shell.execute_reply":"2022-05-31T04:59:19.481165Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"best_answer","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:59:27.339646Z","iopub.execute_input":"2022-05-31T04:59:27.340011Z","iopub.status.idle":"2022-05-31T04:59:27.345689Z","shell.execute_reply.started":"2022-05-31T04:59:27.339980Z","shell.execute_reply":"2022-05-31T04:59:27.344906Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'logit_score': 5.661269, 'answer': 'The European Commission'}"},"metadata":{}}]},{"cell_type":"code","source":"# let's extract all the answers in the batch of 8 documents\nn_best_size = 20\nimport numpy as np\nstart_logits = output.start_logits.cpu().numpy()\nend_logits = output.end_logits.cpu().numpy()\nprint(start_logits.shape[0])\npredicted_ansers = []\nfor idx in range(start_logits.shape[0]):\n    start_indices = np.argsort(start_logits[idx])[-1:-n_best_size-1:-1].tolist()\n    end_indices = np.argsort(end_logits[idx])[-1:-n_best_size-1:-1].tolist()\n    answers = []\n    for each_start_index in start_indices:\n        for each_end_index in end_indices:\n            if(each_start_index<=each_end_index):\n                logit_score = start_logits[idx][each_start_index]+end_logits[idx][each_end_index]\n                context = batch['context'][batch_sample_mapping[idx]]\n                answer_start,_ = batch_offset_mapping[idx][each_start_index]\n                _,answer_end = batch_offset_mapping[idx][each_end_index]\n                answer = context[answer_start:answer_end]\n                answers.append({'logit_score':logit_score,'answer':answer})\n    best_answer = max(answers,key = lambda x: x['logit_score'])\n    predicted_ansers.append({'answer':best_answer['answer']})","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:13:19.692370Z","iopub.execute_input":"2022-05-31T05:13:19.692717Z","iopub.status.idle":"2022-05-31T05:13:20.051716Z","shell.execute_reply.started":"2022-05-31T05:13:19.692688Z","shell.execute_reply":"2022-05-31T05:13:20.050961Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"8\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_ansers","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:14:38.266913Z","iopub.execute_input":"2022-05-31T05:14:38.267286Z","iopub.status.idle":"2022-05-31T05:14:38.272271Z","shell.execute_reply.started":"2022-05-31T05:14:38.267256Z","shell.execute_reply":"2022-05-31T05:14:38.271566Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'answer': 'The European Commission'},\n {'answer': '10 July 1856'},\n {'answer': 'Marion Dorn'},\n {'answer': 'Krasiński Palace Garden'},\n {'answer': 'cloud storage'},\n {'answer': 'that any object can be, essentially uniquely, decomposed into its prime components'},\n {'answer': 'young and the elderly'},\n {'answer': 'October 1948'}]"},"metadata":{}}]},{"cell_type":"code","source":"for gold_answer,predicted_answer in zip(batch['answers'],predicted_ansers):\n    print(f\"gold answer :: {gold_answer['text']} and predicted answer :::: {predicted_answer['answer']}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:18:53.089639Z","iopub.execute_input":"2022-05-31T05:18:53.090002Z","iopub.status.idle":"2022-05-31T05:18:53.096725Z","shell.execute_reply.started":"2022-05-31T05:18:53.089972Z","shell.execute_reply":"2022-05-31T05:18:53.095617Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"gold answer :: ['the Commission', 'The European Commission', 'the Commission', 'the Commission'] and predicted answer :::: The European Commission\ngold answer :: ['1856', '10 July 1856', '1856'] and predicted answer :::: 10 July 1856\ngold answer :: ['Marion Dorn', 'Marion Dorn', 'Marion Dorn'] and predicted answer :::: Marion Dorn\ngold answer :: ['Krasiński Palace Garden', 'Krasiński Palace Garden', 'Krasiński Palace Garden'] and predicted answer :::: Krasiński Palace Garden\ngold answer :: ['cloud storage', 'cloud storage', 'cloud storage service'] and predicted answer :::: cloud storage\ngold answer :: ['any object can be, essentially uniquely, decomposed into its prime components', 'any object can be, essentially uniquely, decomposed into its prime components', 'any object can be, essentially uniquely, decomposed into its prime components', 'any object can be, essentially uniquely, decomposed into its prime components'] and predicted answer :::: that any object can be, essentially uniquely, decomposed into its prime components\ngold answer :: ['the young and the elderly', 'the young and the elderly', 'young and the elderly'] and predicted answer :::: young and the elderly\ngold answer :: ['October 1948', 'October 1948', 'October 1948'] and predicted answer :::: October 1948\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{"id":"1h6u7bfMetPY"}}]}