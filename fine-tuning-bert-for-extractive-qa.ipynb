{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/susantaghosh/fine-tuning-bert-for-extractive-qa?scriptVersionId=96924287\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{"id":"3AzrVylgBfDX"}},{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/susantaghosh1/nlp-notebooks/blob/develop/Fine_Tuning_Extractive_QA_with_BERT_and_Friends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Fine Tuning BERT/RoBERTa/DeBERTa/ALBERT/DistillBERT for extractive QA on Squad dataset","metadata":{"id":"UWOCThD20H8r"}},{"cell_type":"markdown","source":"In this section we will fine-tune Extractive QA on Squad dataset. Encoder-only models like BERT tend to be great at extracting answers to factoid questions like “Who invented the Transformer architecture?” but fare poorly when given open-ended questions like “Why is the sky blue?” In these more challenging cases, encoder-decoder models like T5 and BART are typically used to synthesize the information in a way that’s quite similar to text summarization.","metadata":{"id":"-IdJqLwX0qNr"}},{"cell_type":"markdown","source":"All of those work in the same way: they add a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size,sequence_length,2), indicating the unnormalized scores **[LOGITS]** for start position and end position of the answers for every example in the batch.","metadata":{"id":"SSP9JjD9059z"}},{"cell_type":"markdown","source":"Let's discuss little bit internal working of the model :\n\n1. Question and Context [tokenized version] will be passed together as a pair to the model **[ let's say shape of input to the model is (5,30) where 5 is batch_size and 30 is sequence length [number of tokens in each input]**\n2. Vanilla BERT [OR it's friends] will produce contextualized embeddings for each and every word in the sequence. Shape of output from BERT is **(5,30,768) where 5 is the batch size, 30 is the sequece length and 768 is the embedding dimension of the each token**\n3. Now a linear head will be added on top of each of the tokens and each liner layer will take 768 dim as input and outputs 2 tensors , which we call start_logits and end_logits. Now, shape of output is **(5,30,2)**\n4. Now we will split the start_logits and end_logits where shape of each logits are **(5,30,1)**\n5. Now we will remove the single dimesion from the last dimension of start and end logits or in other words we will squeeze the start and end logits across the last dimesion and now shape of start and end logits will be **(5,30)**\n\n**start_logits = tensor of shape (5,30)**\n**end_logits = tensor of shape (5,30)**\n\n6. Model will take start_positions and end_positions of the answer in the tokenized data as labels\n\nstart_positions (`torch.LongTensor` of shape `(batch_size,)`):\n            Labels for position (index) of the start of the labelled span for computing the token classification loss.Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence are not taken into account for computing the loss.\n\nend_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n            Labels for position (index) of the end of the labelled span for computing the token classification loss.Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence are not taken into account for computing the loss.\n\n**start_positions = tensor of shape (5,)**\n**end_positions = tensor of shape (5,)**\n\n7. Now Cross Entropy loss will be computed between **start_logits and start_positions** and **end_logits and end_positions**.\n\n8. Total loss will be the average loss of **start_logits and start_positions** and end_logits and end_positions** and it will be backpropagated to the model for calculationg the gradients and optimizing the weights\n\nPseudo code for QA Model with BERT\n\nclass PseudoQA(nn.Module):\n\n  def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n\n        self.bert = BertModel(config, add_pooling_layer=False)\n        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n\n        # Initialize weights and apply final processing\n        self.post_init()\n  \n   def forward(\n        self,\n        input_ids: Optional[torch.Tensor] = None,\n        attention_mask: Optional[torch.Tensor] = None,\n        token_type_ids: Optional[torch.Tensor] = None,\n        start_positions: Optional[torch.Tensor] = None,\n        end_positions: Optional[torch.Tensor] = None,\n    ) :\n        \n        outputs = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=inputs_embeds,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n\n        sequence_output = outputs[0] ## ** last hidden state output of bert**\n\n        # ** shape of sequence_output : (batch_size,sequence_length,768) **\n\n        logits = self.qa_outputs(sequence_output)\n        # ** shape of logits : (batch_size,sequence_length,2) **\n        start_logits, end_logits = logits.split(1, dim=-1)\n        # ** shape of start_logits and end_logits : (batch_size,sequence_length,1) **\n        start_logits = start_logits.squeeze(-1).contiguous() # ** shape : (batch_size,sequence_length) **\n        end_logits = end_logits.squeeze(-1).contiguous() # ** shape : (batch_size,sequence_length) **\n\n        total_loss = None\n        if start_positions is not None and end_positions is not None:\n            # If we are on multi-GPU, split add a dimension\n            if len(start_positions.size()) > 1:\n                start_positions = start_positions.squeeze(-1)\n            if len(end_positions.size()) > 1:\n                end_positions = end_positions.squeeze(-1)\n            # sometimes the start/end positions are outside our model inputs, \n            # we ignore these terms\n            ignored_index = start_logits.size(1)\n            start_positions = start_positions.clamp(0, ignored_index)\n            end_positions = end_positions.clamp(0, ignored_index)\n\n            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n            start_loss = loss_fct(start_logits, start_positions)\n            end_loss = loss_fct(end_logits, end_positions)\n            total_loss = (start_loss + end_loss) / 2\n  \n\n","metadata":{"id":"rNXXtkju2Nni"}},{"cell_type":"markdown","source":"Enough of theory!!!! Let's dirty our hands","metadata":{"id":"_bBJUi-iNAuG"}},{"cell_type":"code","source":"%%capture\n!pip install datasets transformers[sentencepiece]\n!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n!pip install scipy sklearn","metadata":{"id":"8wtg2T5g6Epj","execution":{"iopub.status.busy":"2022-06-01T05:27:56.226988Z","iopub.execute_input":"2022-06-01T05:27:56.227401Z","iopub.status.idle":"2022-06-01T05:28:24.557590Z","shell.execute_reply.started":"2022-06-01T05:27:56.227365Z","shell.execute_reply":"2022-06-01T05:28:24.556277Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\ndevice","metadata":{"id":"fRNa7Cx0M8_W","outputId":"647c0f34-eca3-4bc0-e441-5b25f543c001","execution":{"iopub.status.busy":"2022-06-01T05:28:24.559606Z","iopub.execute_input":"2022-06-01T05:28:24.559966Z","iopub.status.idle":"2022-06-01T05:28:26.222985Z","shell.execute_reply.started":"2022-06-01T05:28:24.559929Z","shell.execute_reply":"2022-06-01T05:28:26.222061Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"ZyPHX3ByM_jd","outputId":"9eb721a1-e4d0-46a9-920b-2282937d90e3","execution":{"iopub.status.busy":"2022-06-01T02:59:54.942998Z","iopub.execute_input":"2022-06-01T02:59:54.943823Z","iopub.status.idle":"2022-06-01T02:59:55.711731Z","shell.execute_reply.started":"2022-06-01T02:59:54.943789Z","shell.execute_reply":"2022-06-01T02:59:55.710452Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/bin/bash: nvidia-smi: command not found\n","output_type":"stream"}]},{"cell_type":"code","source":"# load the dataset\n\nfrom datasets import load_dataset\n\nraw_datasets = load_dataset(\"squad\")","metadata":{"id":"yF5FW2LuP4ZN","outputId":"10073e2e-86ec-4090-8ece-22b6cb9f4004","execution":{"iopub.status.busy":"2022-06-01T05:28:47.661410Z","iopub.execute_input":"2022-06-01T05:28:47.661718Z","iopub.status.idle":"2022-06-01T05:28:49.163337Z","shell.execute_reply.started":"2022-06-01T05:28:47.661691Z","shell.execute_reply":"2022-06-01T05:28:49.162233Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac61acc7cdbe48598e41d495ea2650c7"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"id":"EZ43kFkGQB92","outputId":"234e45c7-6549-4295-ed35-379e82259460","execution":{"iopub.status.busy":"2022-06-01T05:34:23.765031Z","iopub.execute_input":"2022-06-01T05:34:23.765451Z","iopub.status.idle":"2022-06-01T05:34:23.771321Z","shell.execute_reply.started":"2022-06-01T05:34:23.765418Z","shell.execute_reply":"2022-06-01T05:34:23.770669Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 87599\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 10570\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Context: \", raw_datasets[\"train\"][0][\"context\"])\nprint(\"Question: \", raw_datasets[\"train\"][0][\"question\"])\nprint(\"Answer: \", raw_datasets[\"train\"][0][\"answers\"])","metadata":{"id":"WmtmryzAQG5e","outputId":"bb0f30e0-9505-4f1f-b772-4839d5f9771f","execution":{"iopub.status.busy":"2022-05-29T11:30:49.996414Z","iopub.execute_input":"2022-05-29T11:30:49.997431Z","iopub.status.idle":"2022-05-29T11:30:50.086318Z","shell.execute_reply.started":"2022-05-29T11:30:49.997389Z","shell.execute_reply":"2022-05-29T11:30:50.085234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(raw_datasets[\"train\"][0][\"answers\"].keys())\nprint(type(raw_datasets[\"train\"][0][\"answers\"]['text']))\nprint(raw_datasets[\"train\"][0][\"answers\"]['text'][0])","metadata":{"id":"yvnINZheQWU3","outputId":"0056e6fb-cf78-4110-8efd-60ec91c345fb","execution":{"iopub.status.busy":"2022-05-29T11:30:50.088119Z","iopub.execute_input":"2022-05-29T11:30:50.089218Z","iopub.status.idle":"2022-05-29T11:30:50.097488Z","shell.execute_reply.started":"2022-05-29T11:30:50.089178Z","shell.execute_reply":"2022-05-29T11:30:50.096378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = raw_datasets[\"train\"][0][\"answers\"]['text'][0]\nanswer_start = raw_datasets[\"train\"][0][\"answers\"]['answer_start'][0]\nanswer_end = answer_start + len(answer)\nanswer_from_context = raw_datasets[\"train\"][0][\"context\"] [answer_start:answer_end]\n","metadata":{"id":"LdlXXwrnQtmG","execution":{"iopub.status.busy":"2022-05-29T11:30:50.099256Z","iopub.execute_input":"2022-05-29T11:30:50.09973Z","iopub.status.idle":"2022-05-29T11:30:50.107758Z","shell.execute_reply.started":"2022-05-29T11:30:50.099685Z","shell.execute_reply":"2022-05-29T11:30:50.106856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer_from_context","metadata":{"id":"58sejr9eRPYw","outputId":"3665f685-8d37-4b2c-87b6-42eb045fb7bb","execution":{"iopub.status.busy":"2022-05-29T11:30:50.109237Z","iopub.execute_input":"2022-05-29T11:30:50.110233Z","iopub.status.idle":"2022-05-29T11:30:50.118052Z","shell.execute_reply.started":"2022-05-29T11:30:50.110193Z","shell.execute_reply":"2022-05-29T11:30:50.117075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"During training, there is only one possible answer. We can double-check this by using the Dataset.filter() method:","metadata":{"id":"-d-TVnBFTL0u"}},{"cell_type":"code","source":"raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)","metadata":{"id":"o1Ut4701TMxO","outputId":"8dc73478-af8a-4291-adab-469fc275ac91","execution":{"iopub.status.busy":"2022-05-29T11:30:50.120459Z","iopub.execute_input":"2022-05-29T11:30:50.121125Z","iopub.status.idle":"2022-05-29T11:30:52.681932Z","shell.execute_reply.started":"2022-05-29T11:30:50.121082Z","shell.execute_reply":"2022-05-29T11:30:52.681039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For evaluation, however, there are several possible answers for each sample, which may be the same or different:","metadata":{"id":"bfbqU4vJTZhm"}},{"cell_type":"code","source":"print(raw_datasets[\"validation\"][0][\"answers\"])\nprint(raw_datasets[\"validation\"][2][\"answers\"])","metadata":{"id":"2qLBYycwTa8A","outputId":"f2599b0e-60a7-4635-ae5a-a7df7ebb140b","execution":{"iopub.status.busy":"2022-05-29T11:30:52.683415Z","iopub.execute_input":"2022-05-29T11:30:52.683972Z","iopub.status.idle":"2022-05-29T11:30:52.690463Z","shell.execute_reply.started":"2022-05-29T11:30:52.683914Z","shell.execute_reply":"2022-05-29T11:30:52.6896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PreProcessing the training data","metadata":{"id":"xM--6qJeTqOf"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"id":"2BktODGOTxon","outputId":"ddbf8d1f-2931-4caf-ec3e-308b4817bde8","execution":{"iopub.status.busy":"2022-05-29T11:30:52.691909Z","iopub.execute_input":"2022-05-29T11:30:52.692475Z","iopub.status.idle":"2022-05-29T11:30:54.692115Z","shell.execute_reply.started":"2022-05-29T11:30:52.692435Z","shell.execute_reply":"2022-05-29T11:30:54.69115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.is_fast,tokenizer.special_tokens_map","metadata":{"id":"yD-6GHL-T23H","outputId":"549dfe47-4711-46dc-ed03-e025e709669f","execution":{"iopub.status.busy":"2022-05-29T11:30:54.693419Z","iopub.execute_input":"2022-05-29T11:30:54.693807Z","iopub.status.idle":"2022-05-29T11:30:54.702086Z","shell.execute_reply.started":"2022-05-29T11:30:54.693769Z","shell.execute_reply":"2022-05-29T11:30:54.701269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can pass to our tokenizer the question and the context together, and it will properly insert the special tokens to form a sentence like this:\n\nCopied\n[CLS] question [SEP] context [SEP]","metadata":{"id":"p34OEOUMUA_X"}},{"cell_type":"markdown","source":"a predicted answer to all the acceptable answers and take the best score. ","metadata":{"id":"mzFGnoH6TlpQ"}},{"cell_type":"markdown","source":"","metadata":{"id":"SsG8T3v3amQX"}},{"cell_type":"code","source":"context = raw_datasets[\"train\"][0][\"context\"]\nquestion = raw_datasets[\"train\"][0][\"question\"]\n\ninputs = tokenizer(question, context,return_offsets_mapping=True)\n","metadata":{"id":"FMfQjUUDUDaH","execution":{"iopub.status.busy":"2022-05-29T11:30:54.706903Z","iopub.execute_input":"2022-05-29T11:30:54.707596Z","iopub.status.idle":"2022-05-29T11:30:54.808269Z","shell.execute_reply.started":"2022-05-29T11:30:54.707553Z","shell.execute_reply":"2022-05-29T11:30:54.807353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(inputs['input_ids']),len(inputs['offset_mapping']),inputs","metadata":{"id":"CEBR0FpJVF9L","outputId":"9c14a329-3f2a-47d5-f7e7-aab822b373c2","execution":{"iopub.status.busy":"2022-05-29T11:30:54.810439Z","iopub.execute_input":"2022-05-29T11:30:54.81113Z","iopub.status.idle":"2022-05-29T11:30:54.819257Z","shell.execute_reply.started":"2022-05-29T11:30:54.811089Z","shell.execute_reply":"2022-05-29T11:30:54.818265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(inputs[\"input_ids\"])\n","metadata":{"id":"uO3b74dQUZlX","outputId":"b6c2379b-faa3-4b9a-a472-49e703c4c8d6","execution":{"iopub.status.busy":"2022-05-29T11:30:54.8209Z","iopub.execute_input":"2022-05-29T11:30:54.821995Z","iopub.status.idle":"2022-05-29T11:30:56.453375Z","shell.execute_reply.started":"2022-05-29T11:30:54.821951Z","shell.execute_reply":"2022-05-29T11:30:56.452564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])","metadata":{"id":"169dwirTUwLf","outputId":"6dc9c854-2839-4dc2-a745-ed70fb017af6","execution":{"iopub.status.busy":"2022-05-29T11:30:56.455031Z","iopub.execute_input":"2022-05-29T11:30:56.455794Z","iopub.status.idle":"2022-05-29T11:30:56.464992Z","shell.execute_reply.started":"2022-05-29T11:30:56.455757Z","shell.execute_reply":"2022-05-29T11:30:56.464119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case the context is not too long, but some of the examples in the dataset have very long contexts that will exceed the maximum length we set (which is 384 in this case).  we will deal with long contexts by creating several training features from one sample of our dataset, with a sliding window between them.\n\nTo see how this works using the current example, we can limit the length to 100 and use a sliding window of 50 tokens. As a reminder, we use:\n\nmax_length to set the maximum length (here 100)\ntruncation=\"only_second\" to truncate the context (which is in the second position) when the question with its context is too long\nstride to set the number of overlapping tokens between two successive chunks (here 50)\nreturn_overflowing_tokens=True to let the tokenizer know we want the overflowing tokens\n\nreturn_offsets_mapping=True to get the positions of the tokens with respect to the input of the tokenizer [for sequence_id =0, position of question otherwise positions of context]","metadata":{"id":"WqU8pIIPbWyo"}},{"cell_type":"code","source":"batch_encoding = tokenizer(question,context,max_length=100,truncation=\"only_second\",stride=50,\n                           return_overflowing_tokens=True,return_offsets_mapping=True)","metadata":{"id":"WbB-14qsb21H","execution":{"iopub.status.busy":"2022-05-29T11:30:56.466568Z","iopub.execute_input":"2022-05-29T11:30:56.466945Z","iopub.status.idle":"2022-05-29T11:30:56.475535Z","shell.execute_reply.started":"2022-05-29T11:30:56.466909Z","shell.execute_reply":"2022-05-29T11:30:56.474511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_encoding.keys(),len(batch_encoding['input_ids'])","metadata":{"id":"trnC18RWc-w5","outputId":"ac04e23a-33e3-44d2-c2b4-73530f5656e9","execution":{"iopub.status.busy":"2022-05-29T11:30:56.478378Z","iopub.execute_input":"2022-05-29T11:30:56.478931Z","iopub.status.idle":"2022-05-29T11:30:56.485772Z","shell.execute_reply.started":"2022-05-29T11:30:56.478904Z","shell.execute_reply":"2022-05-29T11:30:56.484992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_encoding","metadata":{"id":"eYxd_MnpeIAS","outputId":"0e1476b4-c3ed-42cf-95ac-c20b041d0fe9","execution":{"iopub.status.busy":"2022-05-29T11:30:56.487032Z","iopub.execute_input":"2022-05-29T11:30:56.48765Z","iopub.status.idle":"2022-05-29T11:30:56.498491Z","shell.execute_reply.started":"2022-05-29T11:30:56.487612Z","shell.execute_reply":"2022-05-29T11:30:56.497525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_encoding['overflow_to_sample_mapping'] # one long context has been truncated to 4 samples","metadata":{"id":"B13HJSF1dO14","outputId":"af2a18ed-81fd-4560-c59b-672317501136","execution":{"iopub.status.busy":"2022-05-29T11:30:56.499478Z","iopub.execute_input":"2022-05-29T11:30:56.501748Z","iopub.status.idle":"2022-05-29T11:30:56.508531Z","shell.execute_reply.started":"2022-05-29T11:30:56.501703Z","shell.execute_reply":"2022-05-29T11:30:56.507561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_ids = batch_encoding.sequence_ids(0)\nsliced_text = \"\"\nfor idx,tokens,positions in zip(range(len(batch_encoding['input_ids'][0])),batch_encoding['input_ids'][0],batch_encoding['offset_mapping'][0]):\n  if sequence_ids[idx]==0:\n    sliced_text = question[positions[0]:positions[1]]\n  elif sequence_ids[idx]==1:\n    sliced_text = context[positions[0]:positions[1]]\n  print(f\"tokens :: {tokens} and decoed token :: {tokenizer.convert_ids_to_tokens(tokens)} and positions :: {positions} and sliced  text :: {sliced_text}\")  ## positions for special tokens will be (0,0)","metadata":{"id":"8FlXbGwpdYBq","outputId":"06c047b4-1f5e-4483-fc25-e07b93b38998","execution":{"iopub.status.busy":"2022-05-29T11:30:56.510344Z","iopub.execute_input":"2022-05-29T11:30:56.510986Z","iopub.status.idle":"2022-05-29T11:30:56.52155Z","shell.execute_reply.started":"2022-05-29T11:30:56.510947Z","shell.execute_reply":"2022-05-29T11:30:56.52054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's try to encode few more samples together\n\nsample_question =  raw_datasets[\"train\"][2:6][\"question\"] # list of size 4\nsample_context =  raw_datasets[\"train\"][2:6][\"context\"] # list of size 4\nsample_answers = raw_datasets[\"train\"][2:6][\"answers\"]\nsample_question,sample_question[0],sample_context[0],sample_answers[0]","metadata":{"id":"X6fFEkM7mbN4","outputId":"303cc061-4d09-417c-ee34-1f1a0303f0d7","execution":{"iopub.status.busy":"2022-05-29T11:30:56.523478Z","iopub.execute_input":"2022-05-29T11:30:56.523954Z","iopub.status.idle":"2022-05-29T11:30:56.535184Z","shell.execute_reply.started":"2022-05-29T11:30:56.52391Z","shell.execute_reply":"2022-05-29T11:30:56.534174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_encoding = tokenizer(sample_question,sample_context,max_length=100,truncation=\"only_second\",stride=50,\n                           return_overflowing_tokens=True,return_offsets_mapping=True)\nsample_encoding,sample_encoding.keys(),len(sample_encoding['offset_mapping'][0])","metadata":{"id":"Ub23TiWkm4Ao","outputId":"abb9e86a-1f7f-4abb-d7ef-106a4a5feb81","execution":{"iopub.status.busy":"2022-05-29T11:30:56.53742Z","iopub.execute_input":"2022-05-29T11:30:56.537979Z","iopub.status.idle":"2022-05-29T11:30:56.551964Z","shell.execute_reply.started":"2022-05-29T11:30:56.537941Z","shell.execute_reply":"2022-05-29T11:30:56.550779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k,v in sample_encoding.items():\n  print(f\"shape of {k} :: {len(v)}\")  # 4 inputs  results in 19 samples","metadata":{"id":"cUHLHqZInL_Z","outputId":"406073e9-2286-42be-be71-7c5ec36808c8","execution":{"iopub.status.busy":"2022-05-29T11:30:56.553482Z","iopub.execute_input":"2022-05-29T11:30:56.554074Z","iopub.status.idle":"2022-05-29T11:30:56.560684Z","shell.execute_reply.started":"2022-05-29T11:30:56.554034Z","shell.execute_reply":"2022-05-29T11:30:56.559725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"input_ids ,token_type_ids,attention_mask,offset_mapping : each of them will be list of lists and overflow_to_sample_mapping will be simple list","metadata":{"id":"1lniCdkWGAGH"}},{"cell_type":"markdown","source":"let's make the labels. labels will be start_positions and end_positions where each of them will be of shape (batch_size)","metadata":{"id":"01Lpv5pVGiEZ"}},{"cell_type":"markdown","source":"(0, 0) if the answer is not in the corresponding span of the context\n(start_position, end_position) if the answer is in the corresponding span of the context, with start_position being the index of the token (in the input IDs) at the start of the answer and end_position being the index of the token (in the input IDs) where the answer ends","metadata":{"id":"Cz_Hiu5fpI64"}},{"cell_type":"code","source":"sample_answers = raw_datasets[\"train\"][2:6][\"answers\"]\nsample_answers,sample_answers[0]","metadata":{"id":"A00Datp9pLAx","outputId":"e4afa8bf-bf9d-4574-a470-0d9fceb8fc72","execution":{"iopub.status.busy":"2022-05-29T11:30:56.562624Z","iopub.execute_input":"2022-05-29T11:30:56.563293Z","iopub.status.idle":"2022-05-29T11:30:56.573575Z","shell.execute_reply.started":"2022-05-29T11:30:56.563255Z","shell.execute_reply":"2022-05-29T11:30:56.572381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_encoding['overflow_to_sample_mapping']\n","metadata":{"id":"EMM2UPpbrFJ5","outputId":"763c3589-b7b6-4abe-cbe8-335beb6c7d00","execution":{"iopub.status.busy":"2022-05-29T11:30:56.574693Z","iopub.execute_input":"2022-05-29T11:30:56.575566Z","iopub.status.idle":"2022-05-29T11:30:56.584074Z","shell.execute_reply.started":"2022-05-29T11:30:56.575537Z","shell.execute_reply":"2022-05-29T11:30:56.583072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find the original sample\n# find answers start and end char positions of that original sample\n# Find the start and end of the context\n# If the answer is not fully inside the context, label is (0, 0)\n# Otherwise it's the start and end token positions\nsample_mappings = sample_encoding['overflow_to_sample_mapping']\nstart_positions = []\nend_positions = []\nfor i,offset in enumerate(sample_encoding['offset_mapping']):\n  original_sample_id = sample_mappings[i] #find the original sample\n  answer = sample_answers[original_sample_id]\n  answer_start = answer['answer_start'][0]\n  answer_end = answer_start+len(answer['text'][0])\n  sequence_id = sample_encoding.sequence_ids(i)\n  idx = 0\n  while sequence_id[idx]!=1:\n    idx +=1\n  context_start = idx\n  while sequence_id[idx]==1:\n    idx +=1\n  context_end = idx-1\n  if offset[context_start][0]>answer_start or offset[context_end][1]<answer_end:\n    start_positions.append(0)\n    end_positions.append(0)\n  else:\n    idx = context_start\n    while idx <= context_end and offset[idx][0] <= answer_start:\n      idx +=1\n    start_positions.append(idx-1)\n    idx = context_end\n    while idx >= context_start and offset[idx][1] >= answer_end:\n      idx -= 1\n    end_positions.append(idx+1)\nstart_positions, end_positions\n\n\n","metadata":{"id":"Mwr4808TNkD5","outputId":"c4e09c83-2df4-4ad0-f493-4b483887e8b0","execution":{"iopub.status.busy":"2022-05-29T11:30:56.586163Z","iopub.execute_input":"2022-05-29T11:30:56.586909Z","iopub.status.idle":"2022-05-29T11:30:56.604229Z","shell.execute_reply.started":"2022-05-29T11:30:56.586834Z","shell.execute_reply":"2022-05-29T11:30:56.603362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let’s take a look at a few results to verify that our approach is correct. For the first feature we find (83, 85) as labels, so let’s compare the theoretical answer with the decoded span of tokens from 83 to 85 (inclusive):","metadata":{"id":"hqh_JX2ygMdP"}},{"cell_type":"code","source":"idx = 0\nsample_idx = sample_encoding[\"overflow_to_sample_mapping\"][idx]\nanswer = sample_answers[sample_idx][\"text\"][0]\n\nstart = start_positions[idx]\nend = end_positions[idx]\nlabeled_answer = tokenizer.decode(sample_encoding[\"input_ids\"][idx][start : end + 1])\n\nprint(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")","metadata":{"id":"fSIHC2WLf09v","outputId":"7f60c782-e4e6-4221-cc4d-116c24bc4249","execution":{"iopub.status.busy":"2022-05-29T11:30:56.607559Z","iopub.execute_input":"2022-05-29T11:30:56.608361Z","iopub.status.idle":"2022-05-29T11:30:56.617551Z","shell.execute_reply.started":"2022-05-29T11:30:56.608317Z","shell.execute_reply":"2022-05-29T11:30:56.61668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 4\nsample_idx = sample_encoding[\"overflow_to_sample_mapping\"][idx]\nanswer = sample_answers[sample_idx][\"text\"][0]\n\ndecoded_example = tokenizer.decode(sample_encoding[\"input_ids\"][idx])\nprint(f\"Theoretical answer: {answer}, decoded example: {decoded_example}\") #we don’t see the answer inside the context.","metadata":{"id":"TVH1fHz8geo2","outputId":"44cb4ae3-93bc-4b7e-8736-ae7ad6f75162","execution":{"iopub.status.busy":"2022-05-29T11:30:56.619068Z","iopub.execute_input":"2022-05-29T11:30:56.619762Z","iopub.status.idle":"2022-05-29T11:30:56.629393Z","shell.execute_reply.started":"2022-05-29T11:30:56.61972Z","shell.execute_reply":"2022-05-29T11:30:56.628386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 384\nstride = 128\n\n\ndef preprocess_training_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = sample_map[i]\n        answer = answers[sample_idx]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label is (0, 0)\n        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"id":"J6gbBlt2P_ef","execution":{"iopub.status.busy":"2022-05-29T11:30:56.63091Z","iopub.execute_input":"2022-05-29T11:30:56.631487Z","iopub.status.idle":"2022-05-29T11:30:56.648218Z","shell.execute_reply.started":"2022-05-29T11:30:56.63145Z","shell.execute_reply":"2022-05-29T11:30:56.647224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = raw_datasets.map(\n    preprocess_training_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)","metadata":{"id":"BI9g_21Yi-UF","outputId":"206bb5f1-0e47-4c5d-d123-1af4f45f581f","execution":{"iopub.status.busy":"2022-05-29T11:30:56.65211Z","iopub.execute_input":"2022-05-29T11:30:56.653616Z","iopub.status.idle":"2022-05-29T11:32:30.578039Z","shell.execute_reply.started":"2022-05-29T11:30:56.65357Z","shell.execute_reply":"2022-05-29T11:32:30.577166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset","metadata":{"id":"qRSx5u0kovqK","outputId":"a36d1375-9f78-415d-a27e-d275f3e67834","execution":{"iopub.status.busy":"2022-05-29T11:32:30.580125Z","iopub.execute_input":"2022-05-29T11:32:30.580658Z","iopub.status.idle":"2022-05-29T11:32:30.588082Z","shell.execute_reply.started":"2022-05-29T11:32:30.58062Z","shell.execute_reply":"2022-05-29T11:32:30.587402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine Tuning the **model**","metadata":{"id":"-FAj0tksCDiV"}},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"id":"PRXfJP5TlFZV","outputId":"a5ccc05f-e531-47be-bb46-070d9cdbd44b","execution":{"iopub.status.busy":"2022-05-29T11:32:30.589384Z","iopub.execute_input":"2022-05-29T11:32:30.589882Z","iopub.status.idle":"2022-05-29T11:32:50.598122Z","shell.execute_reply.started":"2022-05-29T11:32:30.589843Z","shell.execute_reply":"2022-05-29T11:32:50.597227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"uRzgvx9JlxC7","outputId":"8488d4ea-a01a-4385-d07f-bdd8e9aca6e7","execution":{"iopub.status.busy":"2022-06-01T06:12:09.628235Z","iopub.execute_input":"2022-06-01T06:12:09.628700Z","iopub.status.idle":"2022-06-01T06:12:09.698547Z","shell.execute_reply.started":"2022-06-01T06:12:09.628668Z","shell.execute_reply":"2022-06-01T06:12:09.697555Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"940ae0d2a866418198ad3eba77ef8bae"}},"metadata":{}}]},{"cell_type":"code","source":"!apt install git-lfs","metadata":{"id":"zXdRB9fTnvhi","outputId":"84fbc36c-5a5c-44c5-9552-2ec23f7e8704","execution":{"iopub.status.busy":"2022-06-01T06:12:24.272189Z","iopub.execute_input":"2022-06-01T06:12:24.272752Z","iopub.status.idle":"2022-06-01T06:12:33.063476Z","shell.execute_reply.started":"2022-06-01T06:12:24.272705Z","shell.execute_reply":"2022-06-01T06:12:33.062127Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following NEW packages will be installed:\n  git-lfs\n0 upgraded, 1 newly installed, 0 to remove and 16 not upgraded.\nNeed to get 3316 kB of archives.\nAfter this operation, 11.1 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\nFetched 3316 kB in 3s (1277 kB/s)  \u001b[0m33m\u001b[33m\u001b[33m\u001b[33m\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\n(Reading database ... 105611 files and directories currently installed.)\nPreparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"bert-finetuned-squad\",\n    evaluation_strategy=\"no\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    fp16=True,\n    push_to_hub=True,\n)","metadata":{"id":"4GeGeRDwnOAF","execution":{"iopub.status.busy":"2022-05-29T11:36:04.776911Z","iopub.execute_input":"2022-05-29T11:36:04.777442Z","iopub.status.idle":"2022-05-29T11:36:04.789796Z","shell.execute_reply.started":"2022-05-29T11:36:04.777398Z","shell.execute_reply":"2022-05-29T11:36:04.788843Z"},"outputId":"e04fdc29-c285-4e38-bac4-4b75ebfe4b97","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:36:08.085356Z","iopub.execute_input":"2022-05-29T11:36:08.08602Z","iopub.status.idle":"2022-05-29T11:36:08.090176Z","shell.execute_reply.started":"2022-05-29T11:36:08.085977Z","shell.execute_reply":"2022-05-29T11:36:08.089322Z"},"id":"YPWVlC-yBfDu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['validation'],\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"id":"OyhJ8giuncnS","outputId":"457d5334-2283-474a-839f-ecc3440ac380","execution":{"iopub.status.busy":"2022-05-29T11:36:10.601397Z","iopub.execute_input":"2022-05-29T11:36:10.602372Z","iopub.status.idle":"2022-05-29T14:55:10.76791Z","shell.execute_reply.started":"2022-05-29T11:36:10.602309Z","shell.execute_reply":"2022-05-29T14:55:10.766872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating the model","metadata":{"id":"zxYK3gB6CUcW"}},{"cell_type":"markdown","source":"In huggingface QA pipeline or TransformerReader in haystack inference occurs in below steps\n\n1. Model will output **start_logit and end logit** for each tokens in the batch\n2. We will mask logits of question as well as padding tokens\n3. Convert the logits into probabilities by taking softmax\n4. calculate score of each **(start_logit,end_logit)** pairs by taking product [matrix multiplication] of the two probabilites\n5. look for the pair with the maximum score that yielded a valid answer (e.g., a start_token lower than end_token).","metadata":{"id":"tC7Br4XsCp2l"}},{"cell_type":"markdown","source":"To speed up the evalutation step we will change above steps a little bit\n\n1. We will exclude the softmax step [ logit score will be sufficient]\n2. Instead of calculating core of each (start_logit,end_logit) pairs, we will sort the start and end logits and select **n_best** logits where n_best will be a user defined parameter like 5,20 etc.\n3. Since we will skip the softmax, those scores will be logit scores, and will be obtained by taking the sum of the start and end logits (instead of the product, because of the rule **log(ab) = log(a) + log(b).**","metadata":{"id":"fu2G0okND9Dd"}},{"cell_type":"markdown","source":"Let's make small batch of 100 documents from validation set and evaluate our model","metadata":{"id":"cVayJ7n9JNQ0"}},{"cell_type":"code","source":"batch = raw_datasets[\"validation\"].shuffle().select(range(16))\nbatch","metadata":{"id":"6G92iQabJkEW","outputId":"1e47cfad-47de-438a-f491-e788112214c8","execution":{"iopub.status.busy":"2022-06-01T05:34:51.250751Z","iopub.execute_input":"2022-06-01T05:34:51.251650Z","iopub.status.idle":"2022-06-01T05:34:51.270445Z","shell.execute_reply.started":"2022-06-01T05:34:51.251608Z","shell.execute_reply":"2022-06-01T05:34:51.269502Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'title', 'context', 'question', 'answers'],\n    num_rows: 16\n})"},"metadata":{}}]},{"cell_type":"code","source":"for each_document in batch:\n  break\neach_document","metadata":{"id":"PQeyN5DlJ0UM","outputId":"b3349e1a-77cd-4cac-a708-00c76a65c188","execution":{"iopub.status.busy":"2022-06-01T05:34:56.186780Z","iopub.execute_input":"2022-06-01T05:34:56.187377Z","iopub.status.idle":"2022-06-01T05:34:56.196308Z","shell.execute_reply.started":"2022-06-01T05:34:56.187342Z","shell.execute_reply":"2022-06-01T05:34:56.195564Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'id': '570d529fb3d812140066d6bc',\n 'title': 'Victoria_(Australia)',\n 'context': 'Major events also play a big part in tourism in Victoria, particularly cultural tourism and sports tourism. Most of these events are centred on Melbourne, but others occur in regional cities, such as the V8 Supercars and Australian Motorcycle Grand Prix at Phillip Island, the Grand Annual Steeplechase at Warrnambool and the Australian International Airshow at Geelong and numerous local festivals such as the popular Port Fairy Folk Festival, Queenscliff Music Festival, Bells Beach SurfClassic and the Bright Autumn Festival.',\n 'question': 'Besides cultural events, what other tourist attraction does Victoria have?',\n 'answers': {'text': ['sports', 'sports tourism', 'sports'],\n  'answer_start': [92, 92, 92]}}"},"metadata":{}}]},{"cell_type":"code","source":"trained_model_checkpoint = 'susghosh/bert-finetuned-squad'\nfrom transformers import AutoTokenizer,AutoModelForQuestionAnswering\ntokenizer = AutoTokenizer.from_pretrained(trained_model_checkpoint)\nimport torch\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(trained_model_checkpoint).to(device)","metadata":{"id":"JWJAhRjHKLN9","execution":{"iopub.status.busy":"2022-06-01T05:57:35.000410Z","iopub.execute_input":"2022-06-01T05:57:35.001370Z","iopub.status.idle":"2022-06-01T05:57:44.942616Z","shell.execute_reply.started":"2022-06-01T05:57:35.001331Z","shell.execute_reply":"2022-06-01T05:57:44.941531Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"max_length = 384\nstride = 128\ndef pre_process_small_batch(example):\n   inputs = tokenizer(\n        example['question'],\n        example[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n   return inputs\nbatch_encoding = batch.map(pre_process_small_batch,batched=True,remove_columns=raw_datasets[\"validation\"].column_names,)","metadata":{"id":"45XS1VzKLSpo","outputId":"86aae68c-f0b8-43b3-abef-c25e793fc74b","execution":{"iopub.status.busy":"2022-06-01T05:36:15.435745Z","iopub.execute_input":"2022-06-01T05:36:15.437453Z","iopub.status.idle":"2022-06-01T05:36:15.638799Z","shell.execute_reply.started":"2022-06-01T05:36:15.437380Z","shell.execute_reply":"2022-06-01T05:36:15.637813Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"182b83fdf1834eb18a6588b7c4d7f297"}},"metadata":{}}]},{"cell_type":"code","source":"batch_encoding, len(batch_encoding) ## 100 documents have been splitted among 101 documents","metadata":{"id":"E4PMo0njNEzx","outputId":"493b0f6b-b15b-4fea-b922-0bd10381197c","execution":{"iopub.status.busy":"2022-06-01T05:46:08.870460Z","iopub.execute_input":"2022-06-01T05:46:08.871094Z","iopub.status.idle":"2022-06-01T05:46:08.877824Z","shell.execute_reply.started":"2022-06-01T05:46:08.871053Z","shell.execute_reply":"2022-06-01T05:46:08.876917Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'],\n     num_rows: 16\n }),\n 16)"},"metadata":{}}]},{"cell_type":"code","source":"batch_encoding['offset_mapping'][5]","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:36:46.702816Z","iopub.execute_input":"2022-06-01T05:36:46.703829Z","iopub.status.idle":"2022-06-01T05:36:46.740990Z","shell.execute_reply.started":"2022-06-01T05:36:46.703785Z","shell.execute_reply":"2022-06-01T05:36:46.740199Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[[0, 0],\n [0, 3],\n [4, 7],\n [8, 11],\n [12, 16],\n [17, 21],\n [22, 24],\n [25, 29],\n [30, 33],\n [34, 35],\n [36, 43],\n [44, 46],\n [47, 55],\n [55, 56],\n [0, 0],\n [0, 3],\n [4, 11],\n [12, 19],\n [20, 29],\n [30, 32],\n [33, 36],\n [37, 41],\n [42, 45],\n [46, 47],\n [47, 51],\n [52, 57],\n [58, 65],\n [65, 66],\n [67, 71],\n [72, 75],\n [76, 80],\n [81, 90],\n [91, 95],\n [96, 99],\n [100, 103],\n [104, 111],\n [111, 112],\n [113, 116],\n [117, 121],\n [122, 129],\n [130, 134],\n [135, 140],\n [141, 143],\n [144, 147],\n [148, 152],\n [153, 165],\n [166, 176],\n [176, 177],\n [178, 181],\n [182, 191],\n [192, 201],\n [202, 213],\n [214, 224],\n [225, 231],\n [232, 240],\n [240, 241],\n [242, 247],\n [248, 251],\n [252, 259],\n [259, 260],\n [261, 264],\n [265, 273],\n [274, 276],\n [277, 284],\n [285, 293],\n [294, 300],\n [301, 303],\n [304, 309],\n [310, 315],\n [316, 318],\n [319, 322],\n [323, 329],\n [329, 330],\n [331, 338],\n [339, 349],\n [350, 354],\n [355, 362],\n [363, 368],\n [369, 377],\n [378, 387],\n [388, 390],\n [391, 394],\n [395, 402],\n [403, 405],\n [406, 410],\n [411, 419],\n [420, 427],\n [428, 431],\n [432, 436],\n [436, 437],\n [438, 445],\n [446, 453],\n [454, 464],\n [465, 469],\n [470, 472],\n [473, 475],\n [475, 477],\n [477, 479],\n [479, 484],\n [484, 485],\n [486, 488],\n [488, 490],\n [490, 493],\n [493, 497],\n [497, 498],\n [499, 504],\n [505, 514],\n [514, 515],\n [516, 519],\n [520, 527],\n [528, 534],\n [535, 540],\n [541, 544],\n [545, 548],\n [548, 550],\n [550, 552],\n [553, 557],\n [558, 569],\n [570, 578],\n [579, 581],\n [582, 585],\n [586, 592],\n [593, 597],\n [598, 601],\n [602, 605],\n [606, 610],\n [611, 613],\n [614, 617],\n [618, 624],\n [624, 625],\n [626, 633],\n [634, 641],\n [642, 650],\n [651, 655],\n [656, 660],\n [661, 663],\n [664, 667],\n [668, 672],\n [673, 679],\n [679, 680],\n [681, 684],\n [685, 694],\n [695, 698],\n [699, 701],\n [701, 704],\n [705, 706],\n [706, 709],\n [709, 710],\n [710, 711],\n [711, 714],\n [714, 715],\n [715, 716],\n [717, 725],\n [726, 727],\n [728, 738],\n [739, 745],\n [746, 749],\n [750, 758],\n [759, 761],\n [761, 763],\n [763, 766],\n [766, 769],\n [770, 776],\n [776, 777],\n [778, 783],\n [784, 786],\n [787, 796],\n [797, 802],\n [803, 805],\n [805, 808],\n [808, 813],\n [813, 814],\n [814, 815],\n [816, 819],\n [820, 826],\n [827, 836],\n [837, 839],\n [840, 842],\n [842, 845],\n [846, 855],\n [856, 859],\n [860, 870],\n [871, 873],\n [874, 875],\n [876, 883],\n [884, 888],\n [889, 891],\n [892, 893],\n [894, 897],\n [897, 898],\n [899, 906],\n [907, 915],\n [915, 916],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0],\n [0, 0]]"},"metadata":{}}]},{"cell_type":"code","source":"batch_offset_mapping = batch_encoding['offset_mapping']\nbatch_sample_mapping = batch_encoding['overflow_to_sample_mapping']\nbatch_encoding = batch_encoding.remove_columns(['offset_mapping','overflow_to_sample_mapping'])\nbatch_encoding.set_format('torch')","metadata":{"id":"1Ti0FZpMNo8X","execution":{"iopub.status.busy":"2022-06-01T05:46:27.856325Z","iopub.execute_input":"2022-06-01T05:46:27.857009Z","iopub.status.idle":"2022-06-01T05:46:27.883000Z","shell.execute_reply.started":"2022-06-01T05:46:27.856969Z","shell.execute_reply":"2022-06-01T05:46:27.882192Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"batch_encoding,batch_encoding.column_names","metadata":{"id":"3xNUIopTO3Lf","outputId":"a4f5c250-c1d9-4c6c-f41e-b56ef4de6531","execution":{"iopub.status.busy":"2022-06-01T05:46:30.172693Z","iopub.execute_input":"2022-06-01T05:46:30.173410Z","iopub.status.idle":"2022-06-01T05:46:30.178391Z","shell.execute_reply.started":"2022-06-01T05:46:30.173370Z","shell.execute_reply":"2022-06-01T05:46:30.177784Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['input_ids', 'token_type_ids', 'attention_mask'],\n     num_rows: 16\n }),\n ['input_ids', 'token_type_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"input_for_model ={k : batch_encoding[k].to(device) for k in batch_encoding.column_names}","metadata":{"id":"FSK89asEO-kf","execution":{"iopub.status.busy":"2022-06-01T05:46:33.405421Z","iopub.execute_input":"2022-06-01T05:46:33.406299Z","iopub.status.idle":"2022-06-01T05:46:33.419574Z","shell.execute_reply.started":"2022-06-01T05:46:33.406248Z","shell.execute_reply":"2022-06-01T05:46:33.418342Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n output = model(**input_for_model)","metadata":{"id":"8skd1qwnOwXV","outputId":"32440eb3-d635-4ae6-d664-c0272fade994","execution":{"iopub.status.busy":"2022-06-01T05:46:35.936101Z","iopub.execute_input":"2022-06-01T05:46:35.937034Z","iopub.status.idle":"2022-06-01T05:46:47.577899Z","shell.execute_reply.started":"2022-06-01T05:46:35.936994Z","shell.execute_reply":"2022-06-01T05:46:47.576927Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"output.start_logits.shape,output.end_logits.shape, ## each of the logits should be (batch_size,384)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:46:51.593726Z","iopub.execute_input":"2022-06-01T05:46:51.594137Z","iopub.status.idle":"2022-06-01T05:46:51.600423Z","shell.execute_reply.started":"2022-06-01T05:46:51.594103Z","shell.execute_reply":"2022-06-01T05:46:51.599656Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(torch.Size([16, 384]), torch.Size([16, 384]))"},"metadata":{}}]},{"cell_type":"code","source":"# let's grab the first logit\n# select n_best logits\n#for each start_logits score (each_start_logits,each_end_logits)\n#sort the score\nn_best_size = 20\nimport numpy as np\nidx =0 \nstart_logits = output.start_logits[idx].cpu().numpy()\nend_logits = output.end_logits[idx].cpu().numpy()\nstart_indices = np.argsort(start_logits)[-1:-n_best_size-1:-1].tolist()\nend_indices = np.argsort(end_logits)[-1:-n_best_size-1:-1].tolist()\nanswers = []\nfor each_start_index in start_indices:\n    for each_end_index in end_indices:\n        if(each_start_index<=each_end_index):\n            logit_score = start_logits[each_start_index]+end_logits[each_end_index]\n            context = batch['context'][batch_sample_mapping[idx]]\n            answer_start,_ = batch_offset_mapping[idx][each_start_index]\n            _,answer_end = batch_offset_mapping[idx][each_end_index]\n            answer = context[answer_start:answer_end]\n            answers.append({'logit_score':logit_score,'answer':answer})\nbest_answer = max(answers,key = lambda x: x['logit_score'])","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:05:14.634332Z","iopub.execute_input":"2022-06-01T03:05:14.635245Z","iopub.status.idle":"2022-06-01T03:05:14.741200Z","shell.execute_reply.started":"2022-06-01T03:05:14.635207Z","shell.execute_reply":"2022-06-01T03:05:14.740040Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"best_answer","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:05:18.406370Z","iopub.execute_input":"2022-06-01T03:05:18.406833Z","iopub.status.idle":"2022-06-01T03:05:18.413512Z","shell.execute_reply.started":"2022-06-01T03:05:18.406796Z","shell.execute_reply":"2022-06-01T03:05:18.412762Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'logit_score': -1.6018867, 'answer': 'Diffie–Hellman key exchange'}"},"metadata":{}}]},{"cell_type":"code","source":"# let's extract all the answers in the batch of 8 documents\nn_best_size = 20\nimport numpy as np\nstart_logits = output.start_logits.cpu().numpy()\nend_logits = output.end_logits.cpu().numpy()\nprint(start_logits.shape[0])\npredicted_ansers = []\nfor idx in range(start_logits.shape[0]):\n    start_indices = np.argsort(start_logits[idx])[-1:-n_best_size-1:-1].tolist()\n    end_indices = np.argsort(end_logits[idx])[-1:-n_best_size-1:-1].tolist()\n    answers = []\n    for each_start_index in start_indices:\n        for each_end_index in end_indices:\n            if(each_start_index<=each_end_index):\n                logit_score = start_logits[idx][each_start_index]+end_logits[idx][each_end_index]\n                context = batch['context'][batch_sample_mapping[idx]]\n                id = batch['id'][batch_sample_mapping[idx]]\n                answer_start,_ = batch_offset_mapping[idx][each_start_index]\n                _,answer_end = batch_offset_mapping[idx][each_end_index]\n                answer = context[answer_start:answer_end]\n                answers.append({'logit_score':logit_score,'answer':answer,'id':id})\n    best_answer = max(answers,key = lambda x: x['logit_score'])\n    predicted_ansers.append({'prediction_text':best_answer['answer'],'id':best_answer['id']})","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:05:43.823164Z","iopub.execute_input":"2022-06-01T03:05:43.824059Z","iopub.status.idle":"2022-06-01T03:05:46.104353Z","shell.execute_reply.started":"2022-06-01T03:05:43.824021Z","shell.execute_reply":"2022-06-01T03:05:46.103131Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"16\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_ansers","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:05:49.302307Z","iopub.execute_input":"2022-06-01T03:05:49.302713Z","iopub.status.idle":"2022-06-01T03:05:49.311201Z","shell.execute_reply.started":"2022-06-01T03:05:49.302680Z","shell.execute_reply":"2022-06-01T03:05:49.310016Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[{'prediction_text': 'Diffie–Hellman key exchange',\n  'id': '572996c73f37b319004784b3'},\n {'prediction_text': 'toward the Atlantic', 'id': '5725c071271a42140099d128'},\n {'prediction_text': 'Thomas Edison', 'id': '56e0d54a7aa994140058e76c'},\n {'prediction_text': 'over the age of 18', 'id': '572fdb17b2c2fd140056851f'},\n {'prediction_text': 'the convection of the mantle',\n  'id': '57265d08708984140094c39a'},\n {'prediction_text': 'deep-level', 'id': '57268a8fdd62a815002e88d0'},\n {'prediction_text': 'Émile Girardeau', 'id': '56e108abe3433e1400422b0f'},\n {'prediction_text': 'Asia', 'id': '5726d4a45951b619008f7f6a'},\n {'prediction_text': 'Cape of Good Hope', 'id': '571077ecb654c5140001f909'},\n {'prediction_text': 'Galileo Ferraris', 'id': '56e0dbb57aa994140058e77b'},\n {'prediction_text': 'mercuric oxide', 'id': '571a4d1a4faf5e1900b8a95a'},\n {'prediction_text': \"IPCC does not carry out its own research, it operates on the basis of scientific papers and independently documented results from other scientific bodies, and its schedule for producing reports requires a deadline for submissions prior to the report's final release. In principle, this means that any significant new evidence or events that change our understanding of climate science between this deadline and publication of an IPCC report cannot be included. In an area of science where our scientific understanding is rapidly changing, this has been raised as a serious shortcoming in a body which is widely regarded as the ultimate authority on the science\",\n  'id': '5729517d6aef051400154cca'},\n {'prediction_text': 'Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal',\n  'id': '5710f2e2a58dae1900cd6b74'},\n {'prediction_text': 'ordination order of transitional deacon',\n  'id': '5730d597f6cb411900e244d8'},\n {'prediction_text': 'Yale University', 'id': '5727da564b864d1900163e8f'},\n {'prediction_text': 'Americans', 'id': '572ffabf04bcaa1900d76fa0'}]"},"metadata":{}}]},{"cell_type":"code","source":"for gold_answer,predicted_answer in zip(batch['answers'],predicted_ansers):\n    print(f\"gold answer :: {gold_answer['text']} and predicted answer :::: {predicted_answer['prediction_text']}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:05:57.623502Z","iopub.execute_input":"2022-06-01T03:05:57.623930Z","iopub.status.idle":"2022-06-01T03:05:57.632731Z","shell.execute_reply.started":"2022-06-01T03:05:57.623891Z","shell.execute_reply":"2022-06-01T03:05:57.631903Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"gold answer :: ['RSA', 'RSA', 'RSA', 'RSA'] and predicted answer :::: Diffie–Hellman key exchange\ngold answer :: ['Water on the eastern side flowed toward the Atlantic,', 'toward the Atlantic', 'toward the Atlantic'] and predicted answer :::: toward the Atlantic\ngold answer :: ['Thomas Edison', 'Thomas Edison', 'Thomas Edison'] and predicted answer :::: Thomas Edison\ngold answer :: ['over the age of 18', 'over the age of 18', '18'] and predicted answer :::: over the age of 18\ngold answer :: ['the convecting mantle', 'convection of the mantle', 'convection of the mantle', 'the convecting mantle'] and predicted answer :::: the convection of the mantle\ngold answer :: ['deep-level', 'deep-level', 'deep-level tunnels'] and predicted answer :::: deep-level\ngold answer :: ['Émile Girardeau', 'Émile Girardeau', 'Émile Girardeau,'] and predicted answer :::: Émile Girardeau\ngold answer :: ['Asia', 'Asia', 'Asia'] and predicted answer :::: Asia\ngold answer :: ['at the Cape of Good Hope', 'Cape of Good Hope', 'the Cape of Good Hope'] and predicted answer :::: Cape of Good Hope\ngold answer :: ['Galileo Ferraris', 'Galileo Ferraris', 'the Italian physicist Galileo Ferraris'] and predicted answer :::: Galileo Ferraris\ngold answer :: ['mercuric oxide (HgO)', 'mercuric oxide', 'mercuric oxide', 'mercuric oxide (HgO)', 'mercuric oxide'] and predicted answer :::: mercuric oxide\ngold answer :: ['IPCC', 'IPCC', 'the IPCC'] and predicted answer :::: IPCC does not carry out its own research, it operates on the basis of scientific papers and independently documented results from other scientific bodies, and its schedule for producing reports requires a deadline for submissions prior to the report's final release. In principle, this means that any significant new evidence or events that change our understanding of climate science between this deadline and publication of an IPCC report cannot be included. In an area of science where our scientific understanding is rapidly changing, this has been raised as a serious shortcoming in a body which is widely regarded as the ultimate authority on the science\ngold answer :: ['Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal', 'Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal', 'Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal'] and predicted answer :::: Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal\ngold answer :: ['1996 General Conference', '1996 General Conference the', 'the ordination order of transitional deacon was abolished'] and predicted answer :::: ordination order of transitional deacon\ngold answer :: ['Yale University', 'Yale', 'Yale University'] and predicted answer :::: Yale University\ngold answer :: ['Americans', 'Americans', 'Americans'] and predicted answer :::: Americans\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For computing the metrics , we will load squad metrics and to compute the metrics ","metadata":{}},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"squad\")","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:47:17.050355Z","iopub.execute_input":"2022-06-01T05:47:17.051264Z","iopub.status.idle":"2022-06-01T05:47:19.726686Z","shell.execute_reply.started":"2022-06-01T05:47:17.051224Z","shell.execute_reply":"2022-06-01T05:47:19.725869Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05c0c5aa858c44c5913b707721ca2e1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71438d8ada354048a33a96a8d9b3e7df"}},"metadata":{}}]},{"cell_type":"code","source":"theoretical_answers = [\n    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in batch\n]","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:06:28.082478Z","iopub.execute_input":"2022-06-01T03:06:28.082991Z","iopub.status.idle":"2022-06-01T03:06:28.094690Z","shell.execute_reply.started":"2022-06-01T03:06:28.082949Z","shell.execute_reply":"2022-06-01T03:06:28.093484Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"metric.compute(predictions=predicted_ansers, references=theoretical_answers)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:06:31.499517Z","iopub.execute_input":"2022-06-01T03:06:31.499954Z","iopub.status.idle":"2022-06-01T03:06:31.530423Z","shell.execute_reply.started":"2022-06-01T03:06:31.499919Z","shell.execute_reply":"2022-06-01T03:06:31.529701Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'exact_match': 81.25, 'f1': 86.58719931271477}"},"metadata":{}}]},{"cell_type":"code","source":"validation_dataset = raw_datasets[\"validation\"]\nvalidation_dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:16:36.687335Z","iopub.execute_input":"2022-06-01T04:16:36.687985Z","iopub.status.idle":"2022-06-01T04:16:36.694192Z","shell.execute_reply.started":"2022-06-01T04:16:36.687947Z","shell.execute_reply":"2022-06-01T04:16:36.693179Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'title', 'context', 'question', 'answers'],\n    num_rows: 10570\n})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:17:14.616128Z","iopub.execute_input":"2022-06-01T04:17:14.617031Z","iopub.status.idle":"2022-06-01T04:17:14.631270Z","shell.execute_reply.started":"2022-06-01T04:17:14.616993Z","shell.execute_reply":"2022-06-01T04:17:14.629918Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"encoded_validation_data = validation_dataset.map(pre_process_small_batch,\n                                                 batched=True,\n                                                 remove_columns=raw_datasets[\"validation\"].column_names,)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:17:23.280076Z","iopub.execute_input":"2022-06-01T04:17:23.280681Z","iopub.status.idle":"2022-06-01T04:17:23.542061Z","shell.execute_reply.started":"2022-06-01T04:17:23.280632Z","shell.execute_reply":"2022-06-01T04:17:23.540733Z"},"trusted":true},"execution_count":11,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/2415445817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m encoded_validation_data = validation_dataset.map(pre_process_small_batch,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                  \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                  remove_columns=raw_datasets[\"validation\"].column_names,)\n","\u001b[0;31mNameError\u001b[0m: name 'pre_process_small_batch' is not defined"],"ename":"NameError","evalue":"name 'pre_process_small_batch' is not defined","output_type":"error"}]},{"cell_type":"code","source":"len(encoded_validation_data),len(encoded_validation_data['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:13:27.810779Z","iopub.execute_input":"2022-05-31T07:13:27.811187Z","iopub.status.idle":"2022-05-31T07:13:30.014134Z","shell.execute_reply.started":"2022-05-31T07:13:27.81115Z","shell.execute_reply":"2022-05-31T07:13:30.01324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_offset_mapping = encoded_validation_data['offset_mapping']\neval_sample_mapping = encoded_validation_data['overflow_to_sample_mapping']\nencoded_validation_data = encoded_validation_data.remove_columns(['offset_mapping','overflow_to_sample_mapping'])\nencoded_validation_data.set_format('torch')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:15:16.319738Z","iopub.execute_input":"2022-05-31T07:15:16.320132Z","iopub.status.idle":"2022-05-31T07:15:35.107492Z","shell.execute_reply.started":"2022-05-31T07:15:16.320101Z","shell.execute_reply":"2022-05-31T07:15:35.10662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_validation_data","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:15:35.128614Z","iopub.execute_input":"2022-05-31T07:15:35.129384Z","iopub.status.idle":"2022-05-31T07:15:35.138017Z","shell.execute_reply.started":"2022-05-31T07:15:35.129344Z","shell.execute_reply":"2022-05-31T07:15:35.137103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_for_model ={k : encoded_validation_data[k].to(device) for k in encoded_validation_data.column_names}","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:16:32.016621Z","iopub.execute_input":"2022-05-31T07:16:32.017104Z","iopub.status.idle":"2022-05-31T07:16:32.36925Z","shell.execute_reply.started":"2022-05-31T07:16:32.017061Z","shell.execute_reply":"2022-05-31T07:16:32.368356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n  eval_output = model(**eval_for_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:18:12.020962Z","iopub.execute_input":"2022-05-31T07:18:12.021349Z","iopub.status.idle":"2022-05-31T07:18:12.067585Z","shell.execute_reply.started":"2022-05-31T07:18:12.021316Z","shell.execute_reply":"2022-05-31T07:18:12.066205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 384\nstride = 128\n# make the offset_mapping of questions to None\n# return id of the sample in example_id column\ndef pre_process_eval_data(example):\n    questions = [q.strip() for q in example[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        example[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n    sample_mapping = inputs.pop('overflow_to_sample_mapping')\n    example_ids = []\n    for idx in range(len(inputs['input_ids'])):\n        sequence_ids = inputs.sequence_ids(idx)\n        original_sample = sample_mapping[idx]\n        sample_id = example['id'][original_sample]\n        example_ids.append(sample_id)\n        offsets = inputs['offset_mapping'][idx]\n        inputs['offset_mapping'][idx] = [o if sequence_ids[k]==1 else None for k,o in \n                                       enumerate(offsets)]\n    inputs['example_id'] = example_ids\n    return inputs\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:47:51.862963Z","iopub.execute_input":"2022-06-01T05:47:51.863614Z","iopub.status.idle":"2022-06-01T05:47:51.872192Z","shell.execute_reply.started":"2022-06-01T05:47:51.863573Z","shell.execute_reply":"2022-06-01T05:47:51.871007Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"batch = raw_datasets[\"validation\"].shuffle().select(range(16))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:59:32.071129Z","iopub.execute_input":"2022-06-01T05:59:32.071515Z","iopub.status.idle":"2022-06-01T05:59:32.088912Z","shell.execute_reply.started":"2022-06-01T05:59:32.071481Z","shell.execute_reply":"2022-06-01T05:59:32.087803Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"encoding = batch.map(pre_process_eval_data,batched=True,remove_columns=raw_datasets[\"validation\"].column_names,)\nencoding","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:00:29.408637Z","iopub.execute_input":"2022-06-01T06:00:29.409129Z","iopub.status.idle":"2022-06-01T06:00:29.522058Z","shell.execute_reply.started":"2022-06-01T06:00:29.409090Z","shell.execute_reply":"2022-06-01T06:00:29.521191Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"481160469c694f9cbd9ddbabc1f121b6"}},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n    num_rows: 16\n})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\neval_set_for_model = encoding.remove_columns([\"example_id\", \"offset_mapping\"])\neval_set_for_model.set_format(\"torch\")\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nbatch_model = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n\nwith torch.no_grad():\n    outputs = model(**batch_model)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:00:42.638026Z","iopub.execute_input":"2022-06-01T06:00:42.638427Z","iopub.status.idle":"2022-06-01T06:00:51.677377Z","shell.execute_reply.started":"2022-06-01T06:00:42.638394Z","shell.execute_reply":"2022-06-01T06:00:51.676313Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"outputs.start_logits.shape,outputs.end_logits.shape,","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:01:16.738335Z","iopub.execute_input":"2022-06-01T06:01:16.738708Z","iopub.status.idle":"2022-06-01T06:01:16.746314Z","shell.execute_reply.started":"2022-06-01T06:01:16.738677Z","shell.execute_reply":"2022-06-01T06:01:16.745181Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(torch.Size([16, 384]), torch.Size([16, 384]))"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_validation_dataset = validation_dataset.map(pre_process_eval_data,batched=True,\n                                                     remove_columns=validation_dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:20:45.637972Z","iopub.execute_input":"2022-06-01T04:20:45.638517Z","iopub.status.idle":"2022-06-01T04:21:51.985895Z","shell.execute_reply.started":"2022-06-01T04:20:45.638473Z","shell.execute_reply":"2022-06-01T04:21:51.985069Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"605d438dd1804e2bae7c662e4f5c85dc"}},"metadata":{}}]},{"cell_type":"code","source":"len(tokenized_validation_dataset),len(validation_dataset) # 10570 features have been splitted into 10784 features","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:22:59.019616Z","iopub.execute_input":"2022-06-01T04:22:59.021498Z","iopub.status.idle":"2022-06-01T04:22:59.032148Z","shell.execute_reply.started":"2022-06-01T04:22:59.021430Z","shell.execute_reply":"2022-06-01T04:22:59.031267Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(10784, 10570)"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_validation_dataset['example_id'][:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:15:52.246579Z","iopub.execute_input":"2022-06-01T05:15:52.246975Z","iopub.status.idle":"2022-06-01T05:15:52.308439Z","shell.execute_reply.started":"2022-06-01T05:15:52.246940Z","shell.execute_reply":"2022-06-01T05:15:52.307336Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/270437686.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized_validation_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'example_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tokenized_validation_dataset' is not defined"],"ename":"NameError","evalue":"name 'tokenized_validation_dataset' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"Once we feed our tokeinized data to model, we get start and end logits of shape (no_of_features,sequence_length). Due to long contexts, one original context may have been broken into several features and here what we will do :\n\n1. We will find out which list of features assosiated with that original example\n2. We will iterate through all those features linked with that example and produce one best answer","metadata":{}},{"cell_type":"code","source":"\nmax_answer_length = 30\nn_best = 20\nimport collections\nfrom tqdm.auto import tqdm\nimport numpy as np\ndef compute_metrics(start_logits,end_logits,features,examples):\n    example_to_features = collections.defaultdict(list)\n    for idx,feature in enumerate(features):\n        example_to_features[feature['example_id']].append(idx)\n    predicted_answers =[]\n    for example in tqdm(examples):\n        example_id = example['id']\n        context = example['context']\n        answers = []\n        for feature_index in example_to_features[example_id]:\n            start_logit = start_logits[feature_index]\n            end_logit = end_logits[feature_index]\n            offsets = features['offset_mapping'][feature_index]\n            start_indexes = np.argsort(start_logit)[-1 : -20 - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logit)[-1 : -20 - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    # Skip answers that are not fully in the context\n                    if offsets[start_index] is None or offsets[end_index] is None:\n                        continue\n                    # Skip answers with a length that is either < 0 or > max_answer_length\n                    if (\n                        end_index < start_index\n                        or end_index - start_index + 1 > max_answer_length\n                    ):\n                        continue\n                    answer = {\n                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n                    }\n                    answers.append(answer)\n        # Select the answer with the best score\n        if len(answers) > 0:\n            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n            predicted_answers.append(\n                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n            )\n        else:\n            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n    return metric.compute(predictions=predicted_answers, references=theoretical_answers)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:07:08.884459Z","iopub.execute_input":"2022-06-01T06:07:08.884911Z","iopub.status.idle":"2022-06-01T06:07:08.897079Z","shell.execute_reply.started":"2022-06-01T06:07:08.884873Z","shell.execute_reply":"2022-06-01T06:07:08.896070Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"compute_metrics(outputs.start_logits.cpu().numpy(), outputs.end_logits.cpu().numpy(), encoding, batch)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:07:12.586997Z","iopub.execute_input":"2022-06-01T06:07:12.587404Z","iopub.status.idle":"2022-06-01T06:07:12.779363Z","shell.execute_reply.started":"2022-06-01T06:07:12.587369Z","shell.execute_reply":"2022-06-01T06:07:12.778374Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"069b799ac4d344b5b4a40239ac52e917"}},"metadata":{}},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"{'exact_match': 93.75, 'f1': 96.06481481481481}"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import Repository, get_full_repo_name\n\nmodel_name = \"bert-finetuned-squad-tpu\"\nrepo_name = get_full_repo_name(model_name)\nrepo_name","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:12:41.241321Z","iopub.execute_input":"2022-06-01T06:12:41.241776Z","iopub.status.idle":"2022-06-01T06:12:42.183372Z","shell.execute_reply.started":"2022-06-01T06:12:41.241722Z","shell.execute_reply":"2022-06-01T06:12:42.182264Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"'susghosh/bert-finetuned-squad-tpu'"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{"id":"1h6u7bfMetPY"}}]}