{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install datasets transformers[sentencepiece]\n!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n!pip install scipy sklearn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets = load_dataset(\"squad\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"roberta-large\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:26:12.393863Z","iopub.execute_input":"2022-06-01T07:26:12.394504Z","iopub.status.idle":"2022-06-01T07:26:13.747586Z","shell.execute_reply.started":"2022-06-01T07:26:12.394468Z","shell.execute_reply":"2022-06-01T07:26:13.746891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.is_fast","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:26:16.720261Z","iopub.execute_input":"2022-06-01T07:26:16.720954Z","iopub.status.idle":"2022-06-01T07:26:16.727788Z","shell.execute_reply.started":"2022-06-01T07:26:16.720913Z","shell.execute_reply":"2022-06-01T07:26:16.72675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 384\nstride = 128\n\n\ndef preprocess_training_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = sample_map[i]\n        answer = answers[sample_idx]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label is (0, 0)\n        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:26:18.63302Z","iopub.execute_input":"2022-06-01T07:26:18.633748Z","iopub.status.idle":"2022-06-01T07:26:18.649376Z","shell.execute_reply.started":"2022-06-01T07:26:18.633696Z","shell.execute_reply":"2022-06-01T07:26:18.64852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = raw_datasets[\"train\"].map(\n    preprocess_training_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)\nlen(raw_datasets[\"train\"]), len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:26:24.858056Z","iopub.execute_input":"2022-06-01T07:26:24.858752Z","iopub.status.idle":"2022-06-01T07:27:13.875877Z","shell.execute_reply.started":"2022-06-01T07:26:24.858717Z","shell.execute_reply":"2022-06-01T07:27:13.87486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_validation_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_idx = sample_map[i]\n        example_ids.append(examples[\"id\"][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n        offset = inputs[\"offset_mapping\"][i]\n        inputs[\"offset_mapping\"][i] = [\n            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n        ]\n\n    inputs[\"example_id\"] = example_ids\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:16.930161Z","iopub.execute_input":"2022-06-01T07:27:16.930818Z","iopub.status.idle":"2022-06-01T07:27:16.940013Z","shell.execute_reply.started":"2022-06-01T07:27:16.930771Z","shell.execute_reply":"2022-06-01T07:27:16.939268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset = raw_datasets[\"validation\"].map(\n    preprocess_validation_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"validation\"].column_names,\n)\nlen(raw_datasets[\"validation\"]), len(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:21.318339Z","iopub.execute_input":"2022-06-01T07:27:21.318661Z","iopub.status.idle":"2022-06-01T07:27:47.067573Z","shell.execute_reply.started":"2022-06-01T07:27:21.318629Z","shell.execute_reply":"2022-06-01T07:27:47.066669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\n\ndef compute_metrics(start_logits, end_logits, features, examples):\n    example_to_features = collections.defaultdict(list)\n    for idx, feature in enumerate(features):\n        example_to_features[feature[\"example_id\"]].append(idx)\n\n    predicted_answers = []\n    for example in tqdm(examples):\n        example_id = example[\"id\"]\n        context = example[\"context\"]\n        answers = []\n\n        # Loop through all features associated with that example\n        for feature_index in example_to_features[example_id]:\n            start_logit = start_logits[feature_index]\n            end_logit = end_logits[feature_index]\n            offsets = features[feature_index][\"offset_mapping\"]\n\n            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    # Skip answers that are not fully in the context\n                    if offsets[start_index] is None or offsets[end_index] is None:\n                        continue\n                    # Skip answers with a length that is either < 0 or > max_answer_length\n                    if (\n                        end_index < start_index\n                        or end_index - start_index + 1 > max_answer_length\n                    ):\n                        continue\n\n                    answer = {\n                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n                    }\n                    answers.append(answer)\n\n        # Select the answer with the best score\n        if len(answers) > 0:\n            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n            predicted_answers.append(\n                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n            )\n        else:\n            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n\n    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n    return metric.compute(predictions=predicted_answers, references=theoretical_answers)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:50.523128Z","iopub.execute_input":"2022-06-01T07:27:50.523696Z","iopub.status.idle":"2022-06-01T07:27:50.538311Z","shell.execute_reply.started":"2022-06-01T07:27:50.523655Z","shell.execute_reply":"2022-06-01T07:27:50.537652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:45:40.31329Z","iopub.execute_input":"2022-06-01T06:45:40.313583Z","iopub.status.idle":"2022-06-01T06:46:43.185174Z","shell.execute_reply.started":"2022-06-01T06:45:40.313554Z","shell.execute_reply":"2022-06-01T06:46:43.184097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:55.916638Z","iopub.execute_input":"2022-06-01T07:27:55.916932Z","iopub.status.idle":"2022-06-01T07:27:55.935477Z","shell.execute_reply.started":"2022-06-01T07:27:55.916902Z","shell.execute_reply":"2022-06-01T07:27:55.934094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"bert-finetuned-squad\",\n    evaluation_strategy=\"no\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    fp16=True,\n    push_to_hub=True,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, _, _ = trainer.predict(validation_dataset)\nstart_logits, end_logits = predictions\ncompute_metrics(start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training complete\")","metadata":{},"execution_count":null,"outputs":[]}]}